<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <title>ch007.xhtml</title>
  <style>
  </style>
  <link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css" />
</head>
<body epub:type="bodymatter">
<section id="physical-attacks" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Physical attacks</h1>
<div class="TODO">
<p>This chapter should probably be moved under section ‘Physical access side-channel attacks’ higher-up <a href="https://github.com/llsoftsec/llsoftsecbook/issues/181">#181</a></p>
</div>
<section id="overview" class="level2" data-number="7.1">
<h2 data-number="7.1"><span class="header-section-number">7.1</span> Overview</h2>
<p>There are many types of physical attacks – these attack methods focus on one or multiple physical properties of systems ( e.g. CPU, GPU, crypto hardware), and can either be</p>
<ul>
<li>Passive – just monitoring physical quantities (e.g. side channel information leakage), or</li>
<li>Active – modification of physical quantities, for example, by
<ul>
<li>changing the operation conditions of the system so that the circuit operates outside its specifications (e.g. by changing temperature, or by applying glitches to supply voltage/clock source)</li>
<li>injecting faults to the system (e.g. altering the electrical state of the system using Electromagnetic pulse injection, or laser beam)</li>
<li>physically modifying the system/chip</li>
</ul></li>
</ul>
<p>In the rest of this section, we will focus on a subset of physical attacks:</p>
<ul>
<li>Side channel information leakage</li>
<li>Physical attack using glitches</li>
</ul>
<p>These two forms of attacks can be carried out using low cost hardware, and have been widely demonstrated by researchers on SoCs or microcontrollers developed for IoT (Internet-of-Things) applications.</p>
</section>
<section id="physical-access-side-channel-attacks-1" class="level2" data-number="7.2">
<h2 data-number="7.2"><span class="header-section-number">7.2</span> Physical access side-channel attacks</h2>
<p>If an attacker has physical access to a device, even without debug access, the attacker can collect side channel information about the program execution on a processor. If the processor is used to handle cryptographic operations, the side channel information can be used to deduce the crypto key(s) or the data being processed. Please note that some forms of physical attacks (e.g. fault injection attacks like rowhammer and voltjockey) do not require physical access, but those attacks are not covered in this section.</p>
<section id="how-is-information-leaked" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1"><span class="header-section-number">7.2.1</span> How is information leaked?</h3>
<p>The most common physical access side channel attack method is to capture the voltage or current consumption of the device during its operation. Every time a flip-flop toggles, the switching activity results in a small current spike. Even though there is capacitance on the power distribution connections inside the chip, the toggling of registers (composed of flip-flops) still results in variations in the power supply current, which can be observed easily. Because the connections for delivering power (at the power supply, printed circuit board, on chip packages as well as on the silicon dies) also contain resistance, the variation of electrical current in the chip’s power supply also results in variations in the power supply voltage. Again, this can be observed easily if the attacker has physical access to the device. If an attacker has access to data acquisition equipment that can record the current/voltage/power patterns, he/she can record the “power signature” for different crypto operations, including the power signature using different data inputs. By applying analysis techniques like differential power analysis, the attacker can extract the information being processed. One additional form of side-channel leakage is electro-magnetic radiation. Because the processor’s clock frequency is usually in the radio frequency (RF) range, the wires on the die and the tracks on the PCB become small antennas, and the ripples in the processor’s voltage/current results in radio frequency signals. Although the RF power radiated can be tiny, it still means that an attacker can observe the side-channel leakage if he/she is in close proximity from the device and has the right equipment to amplify and record the RF power signature. However, the risk of such attack can be reduced by reducing the radiation energy level using:</p>
<ul>
<li>Shielding around the device, including ground plate on the circuit board.</li>
<li>Coupling capacitors on power supply tracks on the printed circuit board.</li>
</ul>
<p>Generally, such an attack requires knowledge of radio circuit techniques and the result can be affected by other factors. For example, in normal environments there are many other source of RF noises that affects the accuracy of signal measurement. In a “noisy” environment, the RF signals from various wireless communication gadgets nearby might drown out the signals from the device being monitored.</p>
</section>
<section id="side-channel-leakage-at-instruction-level" class="level3" data-number="7.2.2">
<h3 data-number="7.2.2"><span class="header-section-number">7.2.2</span> Side channel leakage at instruction level</h3>
<p>Instruction executions can result in various forms of side channel leakage:</p>
<p>Cycle timing resulting from conditional branch – A code sequence containing a conditional branch could result in observable side channel leakage. For example, if the power signatures of several code segments are easily recognizable (process A, B and C in the following diagram), it is possible to detect if the conditional branch was taken or not.</p>
<figure>
<img src="../media/file8.svg" style="width:80.0%" alt="leakage of conditional branch" />
<figcaption aria-hidden="true">leakage of conditional branch</figcaption>
</figure>
<p>Cycle timing resulting from specific data values – The execution cycles of some instructions can be dependent on the values of input data, resulting in timing side-channel leakage. E.g., the integer divide instruction in Arm Cortex-M processors.</p>
<figure>
<img src="../media/file9.svg" style="width:80.0%" alt="leakage of execution cycle" />
<figcaption aria-hidden="true">leakage of execution cycle</figcaption>
</figure>
<p>Power variation due to value changes – The power spikes in the power signature are often dependent on a combination of how many bits are set and how many bits have toggled in the register(s) — the so-called Hamming weight and Hamming distance, so the amplitude of the spike could be used to guess the register value in that clock cycle. The power spikes can be caused by a combination of</p>
<ul>
<li>Logic switching due to the operations of an instruction (e.g. power consumed by a single cycle multiplier can be much higher than the power used by a Boolean logic function), and</li>
<li>Logic switching due to changes in data values in the register bank and data paths.</li>
</ul>
<p>The switching activities are dependent on preceding and next operations. If the power signature of the codes around a specific instruction is recognizable, then the data value being process could be guessed.</p>
<figure>
<img src="../media/file10.svg" style="width:80.0%" alt="leakage of number of bit toggled" />
<figcaption aria-hidden="true">leakage of number of bit toggled</figcaption>
</figure>
<p>In some SoC or microcontroller implementations, the power spike effect of the operations can be much higher than the effect of data value changes in the register banks. In such case the program execution flow can be observed, and as a result, might also indirectly leak information about the data that it is processing.</p>
</section>
<section id="countermeasures" class="level3" data-number="7.2.3">
<h3 data-number="7.2.3"><span class="header-section-number">7.2.3</span> Countermeasures</h3>
<p>For normal embedded devices that don’t have physical protection features, there is a much higher chance that power/voltage/radiation side channels can result in information leakage. However, some aspects of timing signature leakage could be reduced:</p>
<ul>
<li>Using data processing instruction with data independent timing for cryptographic operations. In recent Arm architectures (including Armv8-A and Armv8-M), some instructions are architecturally defined as DIT (Data Independent Timing).</li>
<li>For conditional branches where the condition is dependent on secret data, use table branch instead might help reduce timing base leakage (both paths result in a branch). It is not necessary to replace all conditional branch. For example, many loop counters in crypto operation can be independent to the crypto key or input data values, so there is no need to change those loops.</li>
</ul>
<div class="TODO">
<p>There is overlap with section timing-side-channels. How to best consolidate that? <a href="https://github.com/llsoftsec/llsoftsecbook/issues/182">#182</a></p>
</div>
<p>There are additional software techniques to mitigate power leakage. One of the most well-known techniques is masking (e.g. Boolean, multiplicative, affine). When applying software mitigation, software developers need to check that optimizations carried out by compilers (C/C++) do not impact the mitigation, as compilers can be very smart and undo the masking in order to perform faster operations (or reducing code size).</p>
</section>
</section>
<section id="fault-injection-attacks" class="level2" data-number="7.3">
<h2 data-number="7.3"><span class="header-section-number">7.3</span> Fault injection attacks</h2>
<section id="common-forms-of-fault-injection-attacks" class="level3" data-number="7.3.1">
<h3 data-number="7.3.1"><span class="header-section-number">7.3.1</span> Common forms of Fault injection attacks</h3>
<p>If an attacker has physical access to a device, they can also choose to use physical attacks to modify the behavior of the software, for example, prevent the software from setting up certain security features during the device’s initialization sequence. The two most common forms of such attacks are voltage glitching and clock glitching.</p>
<figure>
<img src="../media/file11.svg" style="width:80.0%" alt="common fault injection attacks" />
<figcaption aria-hidden="true">common fault injection attacks</figcaption>
</figure>
<ul>
<li>Voltage glitch attack
<ul>
<li>Using a programmable power supply that can switch the voltage level rapidly, it is possible to reduce/increase the power supply voltage of a chip at specific clock cycle of the software execution. In some case, a precise voltage drop can cause a processor to “skip” an instruction, for example, the write to memory or a hardware register might not be taken. Or if a write has taken place, the actual write value used could be changed by the voltage glitch.</li>
</ul></li>
<li>Clock glitch attack
<ul>
<li>Using a clock switching circuit, it is possible to reduce the width of a clock pulse, or the interval between two clock pulses so that some of the hardware registers are not updated correctly at certain clock edge(s). Similar to voltage glitch, this can make the hardware seems to be skipping an instruction.</li>
</ul></li>
</ul>
<p>Such voltage/clock glitch attack could affect multiple parts in the processors, but sometimes the impact might not lead to any visible error in the operation, leaving the only effect that the processor skipping a memory/register write, or writing an incorrect value. Potentially, a glitch attack could result in other observable effect (e.g. register reset, bit toggle). The analysis of fault injection methods (and their physical effect) and the observable effects at the program or instruction execution level are often referred to as fault models, where one can say that a specific fault injection behaves as an instruction skip, etc. More details about the concept of fault models can be found in the paper <a href="https://arxiv.org/pdf/2003.10513.pdf">“Fault Attacks on Secure Embedded Software: Threats, Design and Evaluation”</a>, where a good illustration of the concept is shown in figure 1 of that paper.</p>
<div class="TODO">
<p>Make the above reference to a paper use bibtex. <a href="https://github.com/llsoftsec/llsoftsecbook/issues/159">#159</a></p>
</div>
<p>Using glitching methods, there are several common ways of attacking a system. For example:</p>
<ul>
<li>Skipping an instruction during setup sequence for security features – e.g. skipping the write to the MPU (Memory Protection Unit)/Security Attribution Unit (SAU) so that the MPU/SAU is not enabled.</li>
<li>Skipping an instruction after a security authentication that branch to an error handling code. As the branch is not taken, the code can continue to operate even a security authentication has failed.</li>
<li>Causing an incorrect value to be written in a memory or hardware. E.g. When writing a crypto key to a crypto accelerator, forcing the key value written to be zero (caused to low voltage on bus hardware).</li>
</ul>
<p>Example: <a href="https://www.youtube.com/watch?v=4u6BAH8mEDw">Attack on TrustZone for Armv8-M</a></p>
<p>There are other forms of physical attacks, but most of them requires significant effort or cost (e.g. cut open the chip package can carry out fault injection or readout secret data on chip).</p>
</section>
<section id="countermeasures-1" class="level3" data-number="7.3.2">
<h3 data-number="7.3.2"><span class="header-section-number">7.3.2</span> Countermeasures</h3>
<p>Ideally, system designers can use hardware (SoCs or microcontroller) that support protection against fault injection. For example, a hardware circuit can include redundancy logic (spatial and temporal). In addition, software developers can make such attack harder by adding checks after the write operations. When applying software mitigation, software developers need to check that optimizations carried out by compilers (C/C++) do not impact the mitigation.</p>
</section>
</section>
</section>
</body>
</html>
