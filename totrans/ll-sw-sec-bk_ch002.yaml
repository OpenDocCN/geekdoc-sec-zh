- en: 2 Memory vulnerability based attacks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 2.1 A bit of background on memory vulnerabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Memory access errors describe memory accesses that, although permitted by a
    program, were not intended by the programmer. These types of errors are usually
    defined [@Hicks2014] by explicitly listing their types, which include:'
  prefs: []
  type: TYPE_NORMAL
- en: buffer overflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: null pointer dereference
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use after free
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use of uninitialized memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: illegal free
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory vulnerabilities are an important class of vulnerabilities that arise
    due to these types of errors, and they most commonly occur due to programming
    mistakes when using languages such as C/C++. These languages do not provide mechanisms
    to protect against memory access errors by default. An attacker can exploit such
    vulnerabilities to leak sensitive data or overwrite critical memory locations
    and gain control of the vulnerable program.
  prefs: []
  type: TYPE_NORMAL
- en: 'Memory vulnerabilities have a long history. The [Morris worm](https://en.wikipedia.org/wiki/Morris_worm)
    in 1988 was the first widely publicized attack exploiting a buffer overflow. Later,
    in the mid-90s, a few famous write-ups describing buffer overflows appeared [@AlephOne1996].
    [Stack buffer overflows](ch002.xhtml#stack-buffer-overflows) were mitigated with
    [stack canaries](ch002.xhtml#stack-buffer-overflows) and [non-executable stacks](ch002.xhtml#stack-buffer-overflows).
    The answer was more ingenious ways to bypass these mitigations: [code reuse attacks](ch002.xhtml#code-reuse-attacks),
    starting with attacks like [return-into-libc](ch002.xhtml#code-reuse-attacks)
    [@Solar1997]. Code reuse attacks later evolved to [Return-Oriented Programming
    (ROP)](ch002.xhtml#return-oriented-programming) [@Shacham2007] and even more complex
    techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: To defend against code reuse attacks, the [Address Space Layout Randomization
    (ASLR)](ch002.xhtml#aslr) and [Control-Flow Integrity (CFI)](ch002.xhtml#control-flow-integrity-cfi)
    measures were introduced. This interaction between offensive and defensive security
    research has been essential to improving security, and continues to this day.
    Each newly deployed mitigation results in attempts, often successful, to bypass
    it, or in alternative, more complex exploitation techniques, and even tools to
    automate them.
  prefs: []
  type: TYPE_NORMAL
- en: Memory safe [@Hicks2014] languages are designed with prevention of such vulnerabilities
    in mind and use techniques such as bounds checking and automatic memory management.
    If these languages promise to eliminate memory vulnerabilities, why are we still
    discussing this topic?
  prefs: []
  type: TYPE_NORMAL
- en: On the one hand, C and C++ remain very popular languages, particularly in the
    implementation of low-level software. On the other hand, programs written in memory
    safe languages can themselves be vulnerable to memory errors as a result of bugs
    in how they are implemented, e.g. a bug in their compiler. Can we fix the problem
    by also using memory safe languages for the compiler and runtime implementation?
    Even if that were as simple as it sounds, unfortunately there are types of programming
    errors that these languages cannot protect against. For example, a logical error
    in the implementation of a compiler or runtime for a memory safe language can
    lead to a memory access error not being detected. We will see examples of such
    logic errors in compiler optimizations in a [later section](#jit-compiler-vulnerabilities).
  prefs: []
  type: TYPE_NORMAL
- en: Given the rich history of memory vulnerabilities and mitigations and the active
    developments in this area, compiler developers are likely to encounter some of
    these issues over the course of their careers. This chapter aims to serve as an
    introduction to this area. We start with a discussion of exploitation primitives,
    which can be useful when analyzing threat models Discuss threat models elsewhere
    in book and refer to that section here [#161](https://github.com/llsoftsec/llsoftsecbook/issues/161).
    We then continue with a more detailed discussion of the various types of vulnerabilities,
    along with their mitigations, presented in a rough chronological order of their
    appearance, and, therefore, complexity.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Exploitation primitives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Newcomers to the area of software security may find themselves lost in many
    blog posts and other publications describing specific memory vulnerabilities and
    how to exploit them. Two very common, yet unfamiliar to a newcomer, terms that
    appear in such publications are *read primitive* and *write primitive*. In order
    to understand memory vulnerabilities and be able to design effective mitigations,
    it’s important to understand what these terms mean, how these primitives could
    be obtained by an attacker, and how they can be used.
  prefs: []
  type: TYPE_NORMAL
- en: An *exploit primitive* is a mechanism that allows an attacker to perform a specific
    operation in the memory space of the victim program. This is done by providing
    specially crafted input to the victim program.
  prefs: []
  type: TYPE_NORMAL
- en: 'A *write primitive* gives the attacker some level of write access to the victim’s
    memory space. The value written and the address written to may be controlled by
    the attacker to various degrees. The primitive, for example, may allow:'
  prefs: []
  type: TYPE_NORMAL
- en: writing a fixed value to an attacker-controlled address, or
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: writing to an address consisting of a fixed base and an attacker-controlled
    offset limited to a specific range (e.g. a 32-bit offset)Consider describing in
    more detail why the range limitation matters[#162](https://github.com/llsoftsec/llsoftsecbook/issues/162),
    or
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: writing to an attacker-controlled base address with a fixed offset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Primitives can be further classified according to more detailed properties.
    See slide 11 of [@Miller2012] for an example.
  prefs: []
  type: TYPE_NORMAL
- en: The most powerful version of a write primitive is an *arbitrary write* primitive,
    where both the address and the value are fully controlled by the attacker.
  prefs: []
  type: TYPE_NORMAL
- en: A *read primitive*, respectively, gives the attacker read access to the victim’s
    memory space. The address of the memory location accessed will be controlled by
    the attacker to some degree, as for the write primitive. A particularly useful
    primitive is an *arbitrary read* primitive, in which the address is fully controlled
    by the attacker.
  prefs: []
  type: TYPE_NORMAL
- en: 'The effects of a write primitive are perhaps easier to understand, as it has
    obvious side-effects: a value is written to the victim program’s memory. But how
    can an attacker observe the result of a read primitive?'
  prefs: []
  type: TYPE_NORMAL
- en: This depends on whether the attack is interactive or non-interactive [@Hu2016].
  prefs: []
  type: TYPE_NORMAL
- en: 'In an *interactive attack*, the attacker gives malicious input to the victim
    program. The malicious input causes the victim program to perform the read the
    attacker instructed it to, and to output the results of that read. This output
    could be any kind of output, for example a network packet that the victim transmits.
    The attacker can observe the result of the read primitive by looking at this output,
    for example parsing this network packet. This process then repeats: the attacker
    sends more malicious input to the victim, observes the output and prepares the
    next input. You can see an example of this type of attack in [@Beer2020], which
    describes a zero-click radio proximity exploit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a *non-interactive (one-shot) attack*, the attacker provides all malicious
    input to the victim program at once. The malicious input triggers multiple primitives
    one after the other, and the primitives are able to observe the effects of the
    preceding operations through the victim program’s state. The input could be, for
    example, in the form of a JavaScript program [@Groß2020], or a PDF file pretending
    to be a GIF [@Beer2021].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The references in this section describe complicated modern exploits. Consider
    linking to simpler exploits, as well as some tutorial-level material. [#163](https://github.com/llsoftsec/llsoftsecbook/issues/163)
  prefs: []
  type: TYPE_NORMAL
- en: How does an attacker obtain these kinds of primitives in the first place? The
    details vary, and in some cases it takes a combination of many techniques, some
    of which are out of scope for this book. But we will be describing a few of them
    in this chapter. For example a stack buffer overflow results in a (restricted)
    write primitive when the input size exceeds what the program expected.
  prefs: []
  type: TYPE_NORMAL
- en: As part of an attack, the attacker will want to execute each primitive more
    than once, since a single read or write operation will rarely be enough to achieve
    their end goal (more on this later). How can primitives be combined to perform
    multiple reads/writes?
  prefs: []
  type: TYPE_NORMAL
- en: In the case of an interactive attack, preparing and sending input to the victim
    program and parsing the output of the victim program are usually done in an external
    program that drives the exploit. The attacker is free to use a programming language
    of their choice, as long as they can interact with the victim program in it. Let’s
    assume, for example, an exploit program in C, communicating with the victim program
    over TCP. In this case, the primitives are abstracted into C functions, which
    prepare and send packets to the victim, and parse the victim’s responses. Using
    the primitives is then as simple as calling these functions. These calls can be
    easily combined with arbitrary computations, all written in C, to form the exploit.
  prefs: []
  type: TYPE_NORMAL
- en: For this cycle of repeated input/output interactions to work, the state of the
    victim program must not be lost between the different iterations of providing
    input and observing output. In other words, the victim process must not be restarted.
  prefs: []
  type: TYPE_NORMAL
- en: It’s interesting to note that while the read/write primitives consist of carefully
    constructed inputs to the victim program, the attacker can view these inputs as
    *instructions* to the victim program. The victim program effectively implements
    an interpreter unintentionally, and the attacker can send instructions to this
    interpreter. This is explored further in [@Dullien2020].
  prefs: []
  type: TYPE_NORMAL
- en: In the case of a non-interactive attack, all computation happens within the
    victim program. The duality of input data and code is even more obvious in this
    case, as the malicious input to the victim can be viewed as the exploit code.
    There are cases for which the input is obviously interpreted as code by the victim
    application as well, as in the case of a JavaScript program given as input to
    a JavaScript engine. In this case, the read/write primitives would be written
    as JavaScript functions, which when called have the unintended side-effect of
    accessing arbitrary memory that a JavaScript program is not supposed to have access
    to. The primitives can be chained together with arbitrary computations, also expressed
    in JavaScript.
  prefs: []
  type: TYPE_NORMAL
- en: There are, however, cases where the correspondence between data and code isn’t
    as obvious. For example, in [@Beer2021], the malicious input consists of a PDF
    file, masquerading as a GIF. Due to an integer overflow bug in the PDF decoder,
    the malicious input leads to an unbounded buffer access, therefore to an arbitrary
    read/write primitive. In the case of JavaScript engine exploitation, the attacker
    would normally be able to use JavaScript operations and perform arbitrary computations,
    making exploitation more straightforward. In this case, there are no scripting
    capabilities officially supported. The attackers, however, take advantage of the
    compression format intricacies to implement a small computer architecture, in
    thousands of simple commands to the decoder. In this way, they effectively *introduce*
    scripting capabilities and are able to express their exploit as a program to this
    architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, we have described read/write primitives. We have also discussed how
    an attacker might perform arbitrary computations:'
  prefs: []
  type: TYPE_NORMAL
- en: in an external program in the case of interactive attacks, or
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: by using scripting capabilities (whether originally supported or introduced
    by the attacker) in non-interactive attacks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assuming an attacker has gained these capabilities, how can they use them to
    achieve their goals?
  prefs: []
  type: TYPE_NORMAL
- en: 'The ultimate goal of an attacker may vary: it may be, among other things, getting
    access to a system, leaking sensitive information or bringing down a service.
    Frequently, a first step towards these wider goals is arbitrary code execution
    within the victim process. We have already mentioned that the attacker will typically
    have arbitrary computation capabilities at this point, but arbitrary code execution
    also involves things like calling arbitrary library functions and performing system
    calls.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some examples of how the attacker may use the obtained primitives:'
  prefs: []
  type: TYPE_NORMAL
- en: Leak information, such as pointers to specific data structures or code, or the
    stack pointer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overwrite the stack contents, e.g. to perform a [ROP attack](ch002.xhtml#return-oriented-programming).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overwrite non-control data, e.g. authorization state. Sometimes this step is
    sufficient to achieve the attacker’s goal, bypassing the need for arbitrary code
    execution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once arbitrary code execution is achieved, the attacker may need to exploit
    additional vulnerabilities in order to escape a process sandbox, escalate privilege,
    etc. Such vulnerability chaining is common, but for the purposes of this chapter
    we will focus on:'
  prefs: []
  type: TYPE_NORMAL
- en: Preventing memory vulnerabilities in the first place, thus stopping the attacker
    from obtaining powerful read/write primitives.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mitigating the effects of read/write primitives, e.g. with mechanisms to maintain
    [Control-Flow Integrity (CFI)](ch002.xhtml#control-flow-integrity-cfi).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2.3 Stack buffer overflows
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A buffer overflow occurs when a read from or write to a [data buffer](https://en.wikipedia.org/wiki/Data_buffer)
    exceeds its boundaries. This typically results in adjacent data structures being
    accessed, which has the potential of leaking or compromising the integrity of
    this adjacent data.
  prefs: []
  type: TYPE_NORMAL
- en: When the buffer is allocated on the stack, we refer to a stack buffer overflow.
    In this section we focus on stack buffer overflows since, in the absence of any
    mitigations, they are some of the simplest buffer overflows to exploit.
  prefs: []
  type: TYPE_NORMAL
- en: The [stack frame](https://en.wikipedia.org/wiki/Call_stack) of a function includes
    important control information, such as the saved return address and the saved
    frame pointer. Overwriting these values unintentionally will typically result
    in a crash, but the overflowing values can be carefully chosen by an attacker
    to gain control of the program’s execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a simple example of a program vulnerable to a stack buffer overflow[1](#fn1):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In the code above, since the length of the argument is not checked before copying
    it into `dst`, we have a potential for a buffer overflow.
  prefs: []
  type: TYPE_NORMAL
- en: 'When looking at code generated for AArch64 with GCC 11.2[2](#fn2), the stack
    layout looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Stack frame layout for stack buffer overflow example](../media/file0.svg)'
  prefs: []
  type: TYPE_IMG
- en: Stack frame layout for stack buffer overflow example
  prefs: []
  type: TYPE_NORMAL
- en: The exact details of the stack frame layout, including the ordering of variables
    and the exact control information stored, will depend on the specific compiler
    version you use and the architecture you compile for.
  prefs: []
  type: TYPE_NORMAL
- en: As can be seen the stack diagram, an overflowing write in function `copy_and_print`
    can overwrite the saved frame pointer (FP) and link register (LR) in `main`’s
    frame. When `copy_and_print` returns, execution continues in `main`. When `main`
    returns, however, execution continues from the address stored in the saved LR,
    which has been overwritten. Therefore, when an attacker can choose the value that
    overwrites the saved LR, it’s possible to control where the program resumes execution
    after returning from `main`.
  prefs: []
  type: TYPE_NORMAL
- en: Before non-executable stacks were mainstream, a common way to exploit these
    vulnerabilities would be to use the overflow to simultaneously write shellcode[3](#fn3)
    to the stack and overwrite the return address so that it points to the shellcode.
    [@AlephOne1996] is a classic example of this technique.
  prefs: []
  type: TYPE_NORMAL
- en: The obvious solution to this issue is to use memory protection features of the
    processor in order to mark the stack (along with other data sections) as non-executable[4](#fn4).
    However, even when the stack is not executable, more advanced techniques can be
    used to exploit an overflow that overwrites the return address. These take advantage
    of code that already exists in the executable or in library code, and will be
    described in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Stack canaries are an alternative mitigation for stack buffer overflows. The
    general idea is to store a known value, called the stack canary, between the buffer
    and the control information (in the example, the saved FP and LR), and to check
    this value before leaving the function. Since an overflow that would overwrite
    the return address is going to overwrite the canary first, a corruption of the
    return address through a stack buffer overflow will be detected.
  prefs: []
  type: TYPE_NORMAL
- en: 'This technique has a few limitations: first of all, it specifically aims to
    protect against stack buffer overflows, and does nothing to protect against stronger
    primitives (e.g. arbitrary write primitives). Control-flow integrity techniques,
    which are described in the next section, aim to protect the integrity of stored
    code pointers against any modification.'
  prefs: []
  type: TYPE_NORMAL
- en: Secondly, since a compiler needs to generate additional instructions for ensuring
    the canary’s integrity, heuristics are usually employed to determine which functions
    are considered vulnerable. The additional instructions are then generated only
    for the functions that are considered vulnerable. Since heuristics aren’t always
    perfect, this poses another potential limitation of the technique. To address
    this, compilers can introduce various levels of heuristics, ranging from applying
    the mitigations only to a small proportion of functions, to applying it universally.
    See, for example, the `-fstack-protector`, `-fstack-protector-strong` and `-fstack-protector-all`
    options offered by both [GCC](https://gcc.gnu.org/onlinedocs/gcc/Instrumentation-Options.html)
    and [Clang](https://clang.llvm.org/docs/ClangCommandLineReference.html#cmdoption-clang-fstack-protector).
  prefs: []
  type: TYPE_NORMAL
- en: Another limitation is the possibility of leaks of the canary value. The canary
    value is often randomized at program start but remains the same during the program’s
    execution. An attacker who manages to obtain the canary value at some point might,
    therefore, be able to reuse the leaked canary value and corrupt control information
    while avoiding detection. Choosing a canary value that includes a null byte (the
    C-style string terminator) might help in limiting the damage of overflows coming
    from string manipulation functions, even when the value is leaked.
  prefs: []
  type: TYPE_NORMAL
- en: Many buffer overflow vulnerabilities result from the use of unsafe library functions,
    such as `gets`, or from the unsafe use of library functions such as `strcpy`.
    There is extensive literature on writing secure C/C++ code, for example [@Seacord2013]
    and [@Dowd2006]. A different approach to limiting the effects of overflows is
    library function hardening, which aims to detect buffer overflows and terminate
    the program gracefully. This involves the introduction of feature macros like
    `_FORTIFY_SOURCE` [@Sharma2014].
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it’s important to mention that not all buffer overflows aim to overwrite
    a saved return address. There are many cases where a buffer overflow can overwrite
    other data adjacent to the buffer, for example an adjacent variable that determines
    whether authorization was successful, or a function pointer that, when modified,
    can modify the program’s control flow according to the attacker’s wishes.
  prefs: []
  type: TYPE_NORMAL
- en: Some of these vulnerabilities can be mitigated with the measures described in
    this section, but often more general measures to ensure memory safety or [Control-Flow
    Integrity](ch002.xhtml#control-flow-integrity-cfi) are necessary. For example,
    in addition to the hardening of specific library functions, compilers can also
    implement automatic bounds checking for arrays where the array bound can be statically
    determined (`-fsanitize=bounds`), as well as various other “sanitizers”. We will
    describe these measures in following sections.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4 Use After Free (UaF)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A *use after free* (UaF) occurs when a variable is used (read and/or written)
    after it has been freed. Although this description assumes manual memory management
    using malloc/new and free/delete (heap allocation), if we think about memory as
    a resource one may apply the same idea more broadly. For example, getting a reference
    to a variable in the stack and using it after it has ended its scope, or somehow
    getting access to freed memory from a garbage collector. It is important to note
    that, although seemingly related, some authors prefer to not mix the definitions.
    For example, the Common Weakness Enumeration (CWE) page [only gives examples](https://cwe.mitre.org/data/definitions/416.html)
    using raw malloc/frees, without any mentions to cases with stack or garbage collector.
    Unless explicitly stated, the rest of this section assumes raw memory management
    with malloc/new and free/delete.
  prefs: []
  type: TYPE_NORMAL
- en: Although some cases of UaF may just lead to unexpected software behavior or
    crashes, other cases may enable attackers to poison data and thereby alter program
    flow. There are many possibilities on how this can happen. Some of them depend
    on how the memory allocator manages its data. For example, if the attacker can
    trick the allocator to return the same address for two different allocation, that
    could lead to controllable data. This is shown in more detail in Example @ex:use-after-free.
    For an overview of heap exploiting techniques, see [@dhavalkapil2022].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The exploit below may not work in every system, as it assumes that calling
    malloc+free+malloc will result in both calls to malloc returning the same pointer.
    The example execution below tricks the software into thinking the user is logged
    in, by taking advantage of the UaF to change the boolean:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, four commands are issued:'
  prefs: []
  type: TYPE_NORMAL
- en: '`auth admin` will allocate the `auth_t` structure for the first time. At this
    point, the user has a name, but is not authorized (`logged_in` is `false`).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`reset` will free the memory (but pointer to `auth` is not set to `nullptr`).
    `service (...)` will allocate a new string, potentially at the same address where
    the `auth_t` structure was previously allocated.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`service aaaaaaaaa0aaaaaaaaa0aaaaaaaaa0121` will end up setting the memory
    previously pointing to an `auth_t`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`login` will use the dangling `auth_t` pointer. If this memory has been reallocated
    to the attacker controlled string, it will appear as if the field `name` is set
    to `aaaaaaaaa0aaaaaaaaa0aaaaaaaaa012` and the boolean `logged_in` to `true`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Detecting UaFs is usually not an easy task, as it depends not only on user
    inputs, but sometimes also on the execution flow. It can get even more complicated
    in multi-threaded environments. Therefore, many different UaF detection tools
    have been built, based on a number of different approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: Some detectors intercept calls to delete / free to inject a known value to the
    variables and then run the software looking for crashes that include that value.
    Another useful tool for detecting UaF is Arm’s MTE (Memory Tagging Extension),
    discussed in section @sec:preventing-and-detecting-memory-errors.
  prefs: []
  type: TYPE_NORMAL
- en: Fuzzing (generating random inputs) can also be useful, potentially used at the
    same time as other tools.
  prefs: []
  type: TYPE_NORMAL
- en: One could also include different algorithms to reduce the probability of exploiting
    use-after-free in allocators as a mitigation strategy, garbage collectors or reference-count
    based memory allocators.
  prefs: []
  type: TYPE_NORMAL
- en: Preventing UaF from happening may involve multiple approaches, depending on
    the context. From simple code changes, such as initializing allocated variables,
    to more elaborate changes, such as changing how the memory allocator works to
    avoid reusing specific memory locations. On top of that, decreasing relevance
    of UaF for attackers can be another interesting perspective (meaning, even if
    a UaF is present, decreasing the likelihood of it being exploitable). For example,
    MTE sync mode can force an application crash as soon as the UaF occurs, while
    Pointer Authentication (PAC) can be used to sign pointers so that even if they
    get poisoned, they cannot be used (more details in section @sec:pointer-authentication
    ).
  prefs: []
  type: TYPE_NORMAL
- en: 'Dive more into UaF detection and mitigations. Suggested starting points:'
  prefs: []
  type: TYPE_NORMAL
- en: Allocators using different algorithms to reduce the probability of exploiting
    use-after-free (this might be a whole section of it’s own?)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Type-aware allocation and deallocation functions, which explains the motivation
    for this feature at https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2025/p2719r5.html#a-concrete-use-case.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Languages that use garbage collection or reference counting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Those are not exaustive lists of tools to detect, mitigate and prevent UaFs.
    But this section’s goal was to give a brief introduction to the topic.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5 Code reuse attacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the early days of memory vulnerability exploitation, attackers could simply
    place shellcode of their choice in executable memory and jump to it. As non-executable
    stack and heap became mainstream, attackers started to reuse code already present
    in an application’s binary and linked libraries instead. A variety of different
    techniques to this effect came to light.
  prefs: []
  type: TYPE_NORMAL
- en: The simplest of these techniques is return-to-libc [@Solar1997]. Instead of
    returning to shellcode that the attacker has injected, the return address is modified
    to return into a library function, such as `system` or `exec`. This technique
    is simpler to use when arguments are also passed on the stack and can therefore
    be controlled with the same stack buffer overflow that is used to modify the address.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5.1 Return-oriented programming
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Return-to-libc attacks restrict an attacker to whole library functions. While
    this can lead to powerful attacks, it has also been demonstrated that it is possible
    to achieve arbitrary computation by combining a number of short instruction sequences
    ending in indirect control transfer instructions, known as **gadgets**. The indirect
    control transfer instructions make it easy for an attacker to execute gadgets
    one after another, by controlling the memory or register that provides each control
    transfer instruction’s target.
  prefs: []
  type: TYPE_NORMAL
- en: In return-oriented programming (ROP) [@Shacham2007], each gadget performs a
    simple operation, for example setting a register, then pops a return address from
    the stack and returns to it. The attacker constructs a fake call stack (often
    called a ROP chain) which ensures a number of gadgets are executed one after another,
    in order to perform a more complex operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'This will hopefully become more clear with an example: a ROP chain for AArch64
    Linux that starts a shell, by calling `execve` with `"/bin/sh"` as an argument.
    [The prototype of the `execve` library function](https://man7.org/linux/man-pages/man2/execve.2.html),
    which wraps the exec system call, is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'For AArch64, `pathname` will be passed in the `x0` register, `argv` will be
    passed in `x1`, and `envp` in `x2`. For starting a shell, it is sufficient to:'
  prefs: []
  type: TYPE_NORMAL
- en: Make `x0` contain a pointer to `"/bin/sh"`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Make `x1` contain a pointer to an array of pointers with two elements:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first element is a pointer to `"/bin/sh"`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The second element is zero (`NULL`).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Make `x2` contain zero (`NULL`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This can be achieved by chaining gadgets to set the registers `x0`, `x1`, `x2`,
    and then returning to `execve` in the C library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s assume we have the following gadgets:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A gadget that loads `x0` and `x1` from the stack:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'A gadget that sets `x2` to zero, but also clears `x0` as a side-effect:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Explain how these gadgets could result from C/C++ code. The current versions
    are slightly tweaked by hand to have more manageable offsets. [#164](https://github.com/llsoftsec/llsoftsecbook/issues/164)
  prefs: []
  type: TYPE_NORMAL
- en: 'Both gadgets also clobber several uninteresting registers, but since `gadget_x2`
    also clears `x0`, it becomes clear that we should use a ROP chain that:'
  prefs: []
  type: TYPE_NORMAL
- en: Returns to `gadget_x2`, which sets `x2` to zero.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Returns to `gadget_x0_x1`, which sets `x0` and `x1` to the desired values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Returns to `execve`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure @fig:rop-control-flow shows this control flow.
  prefs: []
  type: TYPE_NORMAL
- en: '![ROP example control flow](../media/file1.svg)'
  prefs: []
  type: TYPE_IMG
- en: ROP example control flow
  prefs: []
  type: TYPE_NORMAL
- en: '![ROP example fake call stack](../media/file2.svg)'
  prefs: []
  type: TYPE_IMG
- en: ROP example fake call stack
  prefs: []
  type: TYPE_NORMAL
- en: We can achieve this by constructing the fake call stack shown in figure @fig:rop-call-stack,
    where “Original frame” marks the frame in which the address of `gadget_x2` has
    replaced a saved return address that will be loaded and returned to in the future.
    As an alternative, an attacker could place this fake call stack somewhere else,
    for example on the heap, and use a primitive that changes the stack pointer’s
    value instead. This is known as stack pivoting.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this fake call stack contains zero bytes, even without considering
    the exact values of the various return addresses included. An overflow bug that
    is based on a C-style string operation would not allow an attacker to replace
    the stack contents with this fake call stack in one go, since C-style strings
    are [null-terminated](https://en.wikipedia.org/wiki/Null-terminated_string) and
    copying the fake stack contents would stop once the first zero byte is encountered.
    The ROP chain would therefore need to be adjusted so that it doesn’t contain zero
    bytes, for example by initially replacing the zero bytes with a different byte
    and adding some more gadgets to the ROP chain that write zero to those stack locations.
  prefs: []
  type: TYPE_NORMAL
- en: A question that comes up when looking at the stack diagram is “how do we know
    the addresses of these gadgets”? We will talk a bit more about this in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: ROP gadgets like the ones used here may be easy to identify by visual inspection
    of a disassembled binary, but it’s common for attackers to use “gadget scanner”
    tools in order to discover large numbers of gadgets automatically. Such tools
    can also be useful to a compiler engineer working on a code reuse attack mitigation,
    as they can point out code sequences that should be protected and have been missed.
  prefs: []
  type: TYPE_NORMAL
- en: Anything in executable memory can potentially be used as a ROP gadget, even
    if the compiler has not intended it to be code. This includes literal pools which
    are intermingled with code, and, on architectures with variable length instruction
    encoding, returning to the middle of an instruction. In a JIT compiler where the
    attacker might influence what literals are generated this can be particularly
    powerful. For example, on x86, the compiler might have emitted the instruction
    `mov $0xc35f, %ax` which is encoded as the four bytes `66 b8 5f c3`. If the attacker
    can divert execution two bytes into that 4-byte instruction it will execute `5f
    c3`. Those bytes corresponds to the two single byte instructions `pop %rdi; ret`
    which is a useful ROP gadget.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5.2 Jump-oriented programming
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Jump-oriented programming (JOP) [@Bletsch2011] is a variation on ROP, where
    gadgets can also end in indirect branch instructions instead of return instructions.
    The attacker chains a number of such gadgets through a dispatcher gadget, which
    loads pointers one after another from an array of pointers, and branches to each
    one in return. The gadgets used must be set up so that they branch or return back
    to the dispatcher after they’re done. This is demonstrated in figure @fig:jop.
  prefs: []
  type: TYPE_NORMAL
- en: '![JOP example](../media/file3.svg)'
  prefs: []
  type: TYPE_IMG
- en: JOP example
  prefs: []
  type: TYPE_NORMAL
- en: The gadgets in the figure are made up, chosen to highlight that each gadget
    can end in a different type of indirect control flow transfer instruction. Consider
    replacing them with more realistic ones. [#165](https://github.com/llsoftsec/llsoftsecbook/issues/165)
  prefs: []
  type: TYPE_NORMAL
- en: In figure @fig:jop, `x4` initially points to the “dispatch table”, which has
    been modified by the attacker to contain the addresses of the three gadgets they
    want to execute. The dispatcher gadget loads each address in the dispatch table
    one by one and branches to them. The first gadget loads `x0` and `x1` from the
    stack, where the attacker has placed the inputs of their choice. It then loads
    its return address, also modified by the attacker so that it points back to the
    dispatcher gadget, and returns to it. The dispatcher branches to the next gadget,
    which adds `x0` and `x1` and leaves the result in `x0`, branching back to the
    dispatcher through another value loaded from the stack into `x2`. The final gadget
    stores the result of the addition, which remains in `x0`, to the stack, before
    branching to `x2`, which still points to the dispatcher gadget.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5.3 Counterfeit Object-oriented programming
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Counterfeit Object-oriented programming (COOP) [@Schuster2015] is a code reuse
    technique that takes advantage of C++ virtual function calls. A COOP attack takes
    advantage of existing virtual functions and [vtables](https://en.wikipedia.org/wiki/Virtual_method_table),
    and creates fake objects pointing to these existing vtables. The virtual functions
    used as gadgets in the attack are called vfgadgets. To chain vfgadgets together,
    the attacker uses a “main loop gadget”, similar to JOP’s dispatcher gadget, which
    is itself a virtual function that loops over a container of pointers to C++ objects
    and invokes a virtual function on these objects. [@Schuster2015] describes the
    attack in more detail. It is specifically mentioned here as an example of an attack
    that doesn’t depend on directly replacing return addresses and code pointers,
    like ROP and JOP do. Such language-specific attacks are important to consider
    when considering mitigations against code reuse attacks, which will be the topic
    of the next section.
  prefs: []
  type: TYPE_NORMAL
- en: It would be nice to have a small example of a COOP attack, similar to the JOP
    example in the previous section. [#261](https://github.com/llsoftsec/llsoftsecbook/issues/261)
  prefs: []
  type: TYPE_NORMAL
- en: 2.5.4 Sigreturn-oriented programming
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One last example of a code reuse attack that is worth mentioning here is sigreturn-oriented
    programming (SROP) [@Bosman2014]. It is a special case of ROP where the attacker
    creates a fake signal handler frame and calls `sigreturn`. `sigreturn` is a system
    call on many UNIX-type systems which is normally called upon return from a signal
    handler, and restores the state of the process based on the state that has been
    saved on the signal handler’s stack by the kernel previously, on entry to the
    signal handler. The ability to fake a signal handler frame and call `sigreturn`
    gives an attacker a simple way to control the state of the program.
  prefs: []
  type: TYPE_NORMAL
- en: 2.6 Mitigations against code reuse attacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When discussing mitigations against code reuse attacks, it is important to
    keep in mind that there are two capabilities the attacker must have for such attacks
    to work:'
  prefs: []
  type: TYPE_NORMAL
- en: the ability to overwrite return addresses, function pointers or other code pointers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: knowledge of the target addresses to overwrite them with (e.g. libc function
    entry points).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When code reuse attacks were first described, programs used to contain absolute
    code pointers, and needed to be loaded at fixed addresses. The stack base was
    predictable, and libraries were loaded in predictable memory locations. This made
    code reuse attacks simple, as all of the addresses needed for a successful exploit
    were easy to discover. In this section, we’re going to discuss mitigations that
    make it harder for an attacker to obtain these capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: The ability for an attacker to overwrite code pointers often boils down to the
    being able to overwrite them while they are stored in memory, rather than in machine
    registers. Overwriting value in machine registers directly is often not possible.
    Attackers use memory vulnerabilities to be able to overwrite pointers in memory.
    With that in mind, one could assume that code reuse mitigations are not necessary
    for programs written in memory-safe languages, as they should not have any memory
    vulnerabilities. However, most real-life programs written in memory-safe languages
    still contain at least portions of binary code written in unsafe languages. An
    attacker could obtain a write primitive in the unsafe portion of the program,
    and use it to overwrite code pointers in the memory-safe portion of the program.
    Therefore, mitigations against code reuse attacks are still relevant for programs
    written in memory-safe languages.
  prefs: []
  type: TYPE_NORMAL
- en: Another reason that attackers could obtain write primitives in memory-safe programs
    is due to bugs in the compiler or the runtime. This is especially true for JIT-based
    languages, see section @sec:jit-compiler-vulnerabilities for more details.
  prefs: []
  type: TYPE_NORMAL
- en: 2.6.1 ASLR
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Address space layout randomization (ASLR)](https://en.wikipedia.org/wiki/Address_space_layout_randomization)
    makes this more difficult by randomizing the positions of the memory areas containing
    the executable, the loaded libraries, the stack and the heap. ASLR requires code
    to be position-independent. Given enough entropy, the chance that an attacker
    would successfully guess one or more addresses in order to mount a successful
    attack will be greatly reduced.'
  prefs: []
  type: TYPE_NORMAL
- en: Does this mean that code reuse attacks have been made redundant by ASLR? Unfortunately,
    this is not the case. There are various ways in which an attacker can discover
    the memory layout of the victim program. This is often referred to as an “info
    leak” [@Serna2012].
  prefs: []
  type: TYPE_NORMAL
- en: Since we can not exclude code reuse attacks solely by making addresses hard
    to guess, we need to also consider mitigations that prevent attackers from overwriting
    return addresses and other code pointers. Some of the mitigations described [earlier](ch002.xhtml#stack-buffer-overflows),
    like stack canaries and library function hardening, can help in specific situations,
    but for the more general case where an attacker has obtained arbitrary read and
    write primitives, we need something more.
  prefs: []
  type: TYPE_NORMAL
- en: 2.6.2 Control-flow Integrity (CFI)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Control-flow integrity (CFI)](https://en.wikipedia.org/wiki/Control-flow_integrity)
    is a family of mitigations that aim to preserve the intended control flow of a
    program. This is done by restricting the possible targets of indirect branches
    and returns. A scheme that protects indirect jumps and calls is referred to as
    forward-edge CFI, whereas a scheme that protects returns is said to implement
    backward-edge CFI.'
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, a CFI scheme would not allow any control flow transfers that don’t
    occur in a correct program execution. However, different schemes have varying
    granularities. In general, the legal branch targets will be divided into classes,
    with targets in each class treated as equivalent for security purpose. A branch
    is permitted to transfer control to any member of its intended target class.
  prefs: []
  type: TYPE_NORMAL
- en: CFI schemes are sometimes classified as coarse-grained or fine-grained. A coarse-grained
    CFI scheme is one that uses a small number of large equivalence classes, whereas
    a fine-grained scheme uses a larger number of smaller classes, so that the possible
    branch targets from a given location are more restricted (perhaps at a greater
    performance cost).
  prefs: []
  type: TYPE_NORMAL
- en: For example, a CFI scheme that allows an indirect function call to continue
    the execution at the start of any function would be considered coarse-grained.
    If it instead restricted to the subset of functions with the appropriate type
    signature, it would be fine-grained.
  prefs: []
  type: TYPE_NORMAL
- en: Forward-edge CFI schemes often rely on function type checks or use static analysis
    (points-to analysis) to identify potential control flow transfer targets. [@Burow2017]
    compares a number of available CFI schemes based on the precision. For forward-edge
    CFI schemes, for example, schemes are classified based on whether or not they
    perform, among others, flow-sensitive analysis, context-sensitive analysis and
    class-hierarchy analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next few subsections go into a bit more detail on the common CFI schemes.
    These CFI schemes are used in production to harden specific kinds of control flow
    transfers. They include:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Clang CFI](https://clang.llvm.org/docs/ControlFlowIntegrityDesign.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: arm64e, see @McCall2019 and pauthabi, see @Korobeynikov2024
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[kcfi](https://reviews.llvm.org/D119296)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: various shadow stacks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pac-ret, see @Cheeseman2019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Arm BTI, Intel IBT](https://en.wikipedia.org/wiki/Indirect_branch_tracking)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Microsoft Control Flow Guard (CFG)](https://learn.microsoft.com/en-us/windows/win32/secbp/control-flow-guard)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A few of the key properties of the most common CFI schemes.
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | forward- edge? | backward- edge? | fine- grained? | hardware- based?
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Clang CFI | Yes | No | Yes | No |'
  prefs: []
  type: TYPE_TB
- en: '| arm64e/pauthabi | Yes | Yes | Yes | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| kcfi | Yes | No | Yes | No |'
  prefs: []
  type: TYPE_TB
- en: '| shadow stack | No | Yes | Yes | Depends |'
  prefs: []
  type: TYPE_TB
- en: '| pac-ret | No | Yes | Yes | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| BTI, IBT | Yes | No | No | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| Control Flow Guard | Yes | No | No | No |'
  prefs: []
  type: TYPE_TB
- en: There are many more CFI approaches, often academic, but many of them are not
    widely used in production. This book focuses mostly on the deployed CFI schemes.
  prefs: []
  type: TYPE_NORMAL
- en: 2.6.2.1 General CFI principles
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 2.6.2.1.1 Protecting (forward) indirect function calls
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In practice, most in-production CFI schemes harden indirect function calls by
    partitioning all functions present in the program into equivalence classes. Each
    function is assigned a single equivalence class.
  prefs: []
  type: TYPE_NORMAL
- en: For C code, most CFI schemes either put all functions into a single equivalence
    class, or partition functions based on their signature.
  prefs: []
  type: TYPE_NORMAL
- en: For example, arm64e and pauthabi put all C functions in a single equivalence
    class see @McCall2019. Examples of CFI schemes that partition C functions based
    on their signature include [kcfi](https://reviews.llvm.org/D119296) and [clang
    cfi](https://clang.llvm.org/docs/ControlFlowIntegrityDesign.html#forward-edge-cfi-for-indirect-function-calls).
  prefs: []
  type: TYPE_NORMAL
- en: 'In C, consider the following three functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Function `f1` and `f3` have the same signature, but `f2` has a different signature.
    A CFI scheme that partitions functions based on their signature will assign `f1`
    and `f3` to the same equivalence class, and `f2` to a different equivalence class.
  prefs: []
  type: TYPE_NORMAL
- en: Probably the main reason why some CFI schemes put all C functions in a single
    equivalence class, is that real-world C code quite often implicitly casts one
    C function pointer type to another. This is technically incorrect C code, but
    happens to work on most platforms not using fine-grained CFI. Example @ex:qsort-cfi
    illustrates this.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the function `cmp_long` has a different signature than the
    function pointer type expected by `qsort`.
  prefs: []
  type: TYPE_NORMAL
- en: This code will run under CFI schemes that put all C functions in a single equivalence
    class, but will fail under CFI schemes that partition C functions based on their
    signature.
  prefs: []
  type: TYPE_NORMAL
- en: 2.6.2.1.2 Protecting (forward) virtual calls
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Many CFI schemes check that a C++ virtual function call happens on an object
    of the correct dynamic type. A few examples are: clang-cfi, arm64e, pauthabi.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In this example, a very fine-grained CFI scheme should allow the call `a->f()`
    if `a` is an instance of `A`, `B`, `C` or `D`. In other words, it should make
    sure either `A::f`, `B::f`, `C::f` or `D::f` gets called and no other function.
    Similarly, the call `b->f()` should only be allowed if it ends up calling either
    `B::f` or `D::f`, but not `A::f` or `C::f`.
  prefs: []
  type: TYPE_NORMAL
- en: clang-cfi implements this very fine-grained CFI scheme when enabling the [`-fsanitize=cfi-cast-strict`
    option](https://clang.llvm.org/docs/ControlFlowIntegrity.html#strictness), whereas
    arm64e and pauthabi implement a more coarse-grained CFI scheme that only (probabilistically)
    checks whether any call to method `f` is one of the overloaded functions from
    `A::f`, i.e. `A::f`, `B::f`, `C::f` or `D::f`. This is less precise on the call
    `b->f()` above.
  prefs: []
  type: TYPE_NORMAL
- en: 2.6.2.1.3 Protecting (forward) switch jumps
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Switch statements with many cases whose values are densely packed together are
    often implemented using a [jump table](https://en.wikipedia.org/wiki/Branch_table),
    which is an array of pointers or offsets to the code for each case. Ultimately,
    the address to jump to is computed by loading from the jump table, and then an
    indirect jump to the computed address is performed. If an attacker can control
    the value used to index into the jump table, they can make the jump target point
    to a different address, leading to the attacker taking over the control flow.
  prefs: []
  type: TYPE_NORMAL
- en: Most CFI schemes do not protect against this, but arm64e and pauthabi do, as
    explained in the example below. This is also explained in [@McCall2019, slide
    39-40].
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Arm64 generates the following assembly code for the jump table. The comments
    have been added manually for clarity.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In this sequence, if the value in `x0` was loaded from memory, it could potentially
    be attacker controlled. If an attacker can control that value, they can make the
    jump target point to an almost arbitrary address, by loading a word offset value
    from any readable location in the process memory space.
  prefs: []
  type: TYPE_NORMAL
- en: 'To prevent this, arm64e and pauthabi check that the value in `x0` is in range
    before loading the jump table offset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 2.6.2.1.4 Protecting (backward-edge) returns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: When a function is called, the address of the instruction after the call instruction
    is stored in a register or on the stack. That address of the next instruction
    is called the “return address”. When the called function returns, it will use
    an instruction to branch to the return address. This is an indirect control flow,
    since the target of the branch isn’t hard-coded in the instruction, but comes
    from a register or a memory location. If an attacker can change the value of the
    return address, they can redirect the control flow.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Most backward-edge CFI schemes add checks before executing the return instruction
    to verify that the return address hasn’t been tampered with.
  prefs: []
  type: TYPE_NORMAL
- en: '[Shadow stack]]{.index entry=“shadow stack”} approaches store the return address
    on a second stack. Some shadow stack approaches also store the return address
    in the original location in the normal stack. In those, before the return is executed,
    it verifies that the return value on both the regular stack and the shadow stack
    are equal. All shadow stack approaches have mechanisms to make it hard to impossible
    for an attacker to overwrite the return address on the shadow stack.'
  prefs: []
  type: TYPE_NORMAL
- en: A software-only implementation is the clang shadow stack, which is explained
    in more detail in section @sec:clang-shadow-stack. Hardware-supported shadow stacks
    include [Arm’s Guarded control stack (GCS)](https://community.arm.com/arm-community-blogs/b/architectures-and-processors-blog/posts/arm-a-profile-architecture-2022),
    and [Intel’s CET Shadow Stack](https://www.intel.com/content/www/us/en/content-details/785687/complex-shadow-stack-updates-intel-control-flow-enforcement-technology.html).
  prefs: []
  type: TYPE_NORMAL
- en: 2.6.2.1.5 Other code pointers that may need protection
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Anytime a code pointer is stored in memory, it can potentially be modified
    by an attacker with a write primitive. The previous sections gave examples of
    how code pointers may originate from various source code constructs, such as function
    pointers, vtables, return addresses, etc. This list isn’t exhaustive, and there
    are more source code constructs that can lead to code pointers being stored in
    memory, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: C++ co-routines are typically implemented using structures containing code pointers.
    Abusing these has recently been coined as [Coroutine Frame-Oriented Programming
    (CFOP)](https://www.usenix.org/conference/usenixsecurity25/presentation/bajo).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Procedure Linkage Table (PLT) and the [Global Offset Table(GOT)](https://en.wikipedia.org/wiki/Global_Offset_Table)
    often contain code pointers. One common way to protect these from being overwritten
    by an attacker is to make these tables [read-only during program startup](https://www.redhat.com/en/blog/hardening-elf-binaries-using-relocation-read-only-relro).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Signal handlers and signal handler frames contain code pointers, see @sec:sigreturn-oriented-programming
    for more details. Should we list examples of indirect control flow from other
    languages too?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2.6.2.2 Detailed descriptions of a few CFI schemes
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Below, we explore a few CFI schemes in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: Clang CFI in section @sec:clang-cfi
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clang Shadow Stack in section @sec:clang-shadow-stack
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pointer Authentication-based CFI schemes:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pac-ret in section @sec:pac-ret
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: arm64e and pauthabi in section @sec:arm64e-pauthabi
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Branch Target Identification (BTI) in section @sec:bti
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2.6.2.2.1 Clang CFI
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[Clang’s CFI](https://clang.llvm.org/docs/ControlFlowIntegrity.html) includes
    a variety of forward-edge control-flow integrity checks. These include checking
    that the target of an indirect function call is an address-taken function of the
    correct type.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When compiling with `-fsanitize=cfi -flto -fvisibility=hidden` [5](#fn5), the
    code for `call_foo` would look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This code looks complicated, but what it does is check that the virtual table
    pointer (vptr) of the argument points to the vtable of `A` or of `B`, which are
    stored consecutively and are the only allowed possibilities. The checks generated
    for different types of control-flow transfers are similar.
  prefs: []
  type: TYPE_NORMAL
- en: 2.6.2.2.2 Clang Shadow Stack
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Clang also implements a backward-edge CFI scheme known as [Shadow Stack](https://clang.llvm.org/docs/ShadowCallStack.html).
    In Clang’s implementation, a separate stack is used for return addresses, which
    means that stack-based buffer overflows cannot be used to overwrite return addresses.
    The address of the shadow stack is randomized and kept in a dedicated register,
    with care taken so that it is never leaked, which means that an arbitrary write
    primitive cannot be used against the shadow stack unless its location is discovered
    through some other means.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, when compiling with `-fsanitize=shadow-call-stack -ffixed-x18`
    [6](#fn6), the code generated for the `main` function from the [earlier stack
    buffer overflow example](#stack-buffer-overflow) will look something like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: You can see that the shadow stack address is kept in `x18`. The return address
    is also saved on the “normal” stack for compatibility with unwinders, but it’s
    not actually used for the function return.
  prefs: []
  type: TYPE_NORMAL
- en: 2.6.2.2.3 Pointer Authentication
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In addition to software implementations, there are a number of hardware-based
    CFI implementations. A hardware-based implementation has the potential to offer
    improved protection and performance compared to an equivalent software-only CFI
    scheme.
  prefs: []
  type: TYPE_NORMAL
- en: One such example is Pointer Authentication [@Rutland2017], an Armv8.3 feature,
    supported only in AArch64 state, that can be used to mitigate code reuse attacks.
  prefs: []
  type: TYPE_NORMAL
- en: Pointer Authentication computes a pointer *signature* for a given address, called
    a Pointer Authentication Code (PAC), see figure @fig:pauth-sign-auth. The PAC
    code is stored in the upper bits of the pointer which are otherwise unused.
  prefs: []
  type: TYPE_NORMAL
- en: A pointer with a PAC code in the upper bits is called a *signed pointer*. A
    non-signed pointer is called a *raw pointer*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The general idea behind Pointer Authentication is that attackers will try to
    overwrite a pointer in memory using a memory vulnerability. Pointer Authentication
    aims to detect when an attacker has overwritten a pointer in memory. It does this
    by making sure that pointers:'
  prefs: []
  type: TYPE_NORMAL
- en: are always signed when they are in memory, and
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: between loading the pointer into a register and using it, the pointer is authenticated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the authentication fails, the program will fault.
  prefs: []
  type: TYPE_NORMAL
- en: Different hardening schemes are possible with pointer authentication, depending
    on which kinds of pointers get signed, such as only return addresses, all function
    pointers, or more.
  prefs: []
  type: TYPE_NORMAL
- en: 'An essential aspect of pointer authentication being useful is to make it hard
    for an attacker to construct the correct PAC that will pass authentication. To
    achieve that, next to the address, 2 other inputs are used to compute the PAC:
    a so-called key and a modifier:'
  prefs: []
  type: TYPE_NORMAL
- en: The key is a secret value that is not directly accessible to software, so that
    an attacker cannot retrieve the key value. This makes it hard for an attacker
    to compute the PAC value for a given address off-line. The key can be thought
    of as a [pepper](https://en.wikipedia.org/wiki/Pepper_(cryptography))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We also want to avoid that an attacker could take a signed pointer from one
    context in your program and use it in a different context. The modifier is a value
    that is specific to the context in which the pointer is used. Different hardening
    schemes will use different modifiers. Two examples of different hardening schemes
    built on top of Pointer Authentication are described in sections @sec:pac-ret
    (the pac-ret hardening scheme) and @sec:arm64e-pauthabi (the arm64e/pauthabi hardening
    scheme). The modifier can be thought of as a [salt](https://en.wikipedia.org/wiki/Salt_(cryptography)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When an attacker successfully takes a signed pointer from one context and overwrites
    another pointer in another context with it, this is called a pointer substitution
    attack. Using different modifiers for different contexts makes pointer substitution
    attacks harder.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![AArch64 sign and authenticate operations to convert raw pointers to signed
    pointers and vice versa](../media/file4.svg)'
  prefs: []
  type: TYPE_IMG
- en: AArch64 sign and authenticate operations to convert raw pointers to signed pointers
    and vice versa
  prefs: []
  type: TYPE_NORMAL
- en: 'Pointer authentication instructions as described above can be used to implement
    a wide variety of hardening schemes. In this book, we only cover the two that
    are used in production on billions of devices in more detail: pac-ret and arm64e/pauthabi.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Other hardening schemes based on Pointer Authentication which we’re not covering
    further include: PACStack [@Liljestrand2021], Camouflage [@DenisCourmont2021],
    PAL [@Yoo2021], PTAuth [@farkhani2021], PAC it up [@Liljestrand2019], FIPAC [@Schilling2022],
    [structure protection](https://discourse.llvm.org/t/rfc-structure-protection-a-family-of-uaf-mitigation-techniques/85555)
    and more. Some of these harden binaries against attacks also in other ways than
    protecting control flow.'
  prefs: []
  type: TYPE_NORMAL
- en: '2.6.2.2.3.1 pac-ret: Backward-Edge CFI'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Clang](https://clang.llvm.org/docs/ClangCommandLineReference.html#aarch64)
    and [GCC](https://gcc.gnu.org/onlinedocs/gcc/AArch64-Options.html) both use Pointer
    Authentication for return address signing, when compiling with the `-mbranch-protection=pac-ret`
    flag. How it works is easiest to explain by example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'When compiling the `main` function from example @ex:stack-buffer-overflow with
    `pac-ret` enabled, the compiler will produce:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Notice the `paciasp` and `autiasp` instructions. At entry to this function,
    the return address, i.e. the address the function will jump back to when executing
    the `ret` instruction at the end, is stored in register `x30`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The instruction `paciasp` computes a PAC for the return address in register
    `x30`, and stores it in the upper bits of `x30`. The PAC is computed from the
    following “inputs”:'
  prefs: []
  type: TYPE_NORMAL
- en: The address in `x30`, which is the return address,
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Secret key `IA`, as indicated by the `ia` in instruction `paciasp`. That key
    is not accessible by the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As a modifier, the current value of the stack pointer (`sp`), as indicated by
    `sp` in the instruction `paciasp`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After the `paciasp` instruction, the value in `x30` is a signed pointer. The
    `stp` instruction stores the signed pointer to memory. Under the usual threat
    model, an attacker with a write primitive can modify the value while it is in
    memory. Therefore, after the value is loaded into `x30` again, by the `ldp` instruction,
    it should be considerded to be potentially tampered with.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the compiler inserts the `autiasp` instruction between loading the
    signed pointer from memory and using it in the `ret` instruction. The `autiasp`
    instruction verifies the PAC in the upper bits of `x30`, taking into account the
    secret key `IA` and modifier `sp`. If the PAC is correct, which will be the case
    in normal execution, the extension bits of the address are restored, so that the
    address can be used in the `ret` instruction. However, if the PAC is incorrect,
    the upper bits will be corrupted so that subsequent uses of the address (such
    as in the `ret` instruction) will result in a fault.
  prefs: []
  type: TYPE_NORMAL
- en: 'By making sure we don’t store any return addresses without a PAC, we can significantly
    reduce the effectiveness of ROP attacks: since the secret key is not retrievable
    by an attacker, an attacker cannot calculate the correct PAC for a given address
    and modifier, and is restricted to guessing it.'
  prefs: []
  type: TYPE_NORMAL
- en: The probability of success when guessing a PAC depends on the exact number of
    PAC bits available in a given system configuration.
  prefs: []
  type: TYPE_NORMAL
- en: The authenticated pointers are vulnerable to pointer substitution attacks, where
    a pointer that has been signed with a given modifier is replaced with a different
    pointer that has also been signed with the same modifier. In the `pac-ret` scheme,
    this is mitigated by using the stack pointer as the modifier, which limits reuse
    of signed return address pointers to function frames that happen to have the same
    stack pointer value.
  prefs: []
  type: TYPE_NORMAL
- en: '2.6.2.2.3.2 arm64e and pauthabi: Forward-Edge CFI'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The use of pauth in arm64e or pauthabi should be explained in more detail, including
    the concepts of signing and authentication oracles [#259](https://github.com/llsoftsec/llsoftsecbook/issues/259)
  prefs: []
  type: TYPE_NORMAL
- en: Pointer Authentication can also be used more widely, for example to implement
    a forward-edge CFI scheme, as is done in the arm64e ABI [@McCall2019]. The Pointer
    Authentication instructions, however, are generic enough to also be useful in
    implementing more general memory safety measures, beyond CFI.
  prefs: []
  type: TYPE_NORMAL
- en: 2.6.2.2.4 BTI and other coarse-grained CFI schemes
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[Branch Target Identification (BTI)](https://developer.arm.com/documentation/102433/0100/Jump-oriented-programming?lang=en),
    introduced in Armv8.5, offers coarse-grained forward-edge protection. With BTI,
    the locations that are targets of indirect branches have to be marked with a new
    instruction, `BTI`. There are four different types of BTI instructions that permit
    different types of indirect branches (indirect jump, indirect call, both, or none).
    An indirect branch to a non-BTI instruction or the wrong type of BTI instruction
    will raise a Branch Target Exception.'
  prefs: []
  type: TYPE_NORMAL
- en: Both Clang and GCC support generating BTI instructions, with the `-mbranch-protection=bti`
    flag, or, to enable both BTI and return address signing with Pointer Authentication,
    `-mbranch-protection=standard`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two aspects of BTI can simplify its deployment: individual pages can be marked
    as guarded or unguarded, with BTI checks as described above only applying to indirect
    branches targeting guarded pages. In addition to this, the BTI instruction has
    been assigned to the hint space, therefore it will be executed as a no-op in cores
    that do not support BTI, aiding its adoption.'
  prefs: []
  type: TYPE_NORMAL
- en: Another implementation of coarse-grained forward-edge CFI is Windows [Control
    Flow Guard](https://docs.microsoft.com/en-us/windows/win32/secbp/control-flow-guard),
    which only allows indirect calls to functions that are marked as valid indirect
    control flow targets.
  prefs: []
  type: TYPE_NORMAL
- en: 2.6.2.3 CFI implementation pitfalls
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When implementing CFI measures like the ones described here, it is important
    to be aware of known weaknesses that affect similar schemes. [@Conti2015] describes
    how CFI implementations can suffer when certain registers are spilled on the stack,
    where they could be controlled by an attacker. For example, if a register that
    contains a function pointer that has just been validated gets spilled, the check
    can effectively be bypassed by overwriting the spilled pointer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having discussed various mitigations against code reuse attacks, it’s time
    to turn our attention to a different type of attacks, which do not try to overwrite
    code pointers: attacks against non-control data, which will be the topic of the
    next section.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.7 Non-control data attacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous sections, we have focused on subverting control flow by overwriting
    control data, which are used to change the value of the program counter, such
    as return addresses and function pointers. Since these types of attacks are prominent,
    many mitigations have been designed with the goal of maintaining control-flow
    integrity. Non-control data attacks entry=“non-control data attacks”}, also known
    as data-only attacks, can completely bypass these mitigations, since the data
    they modify is not the control data that these mitigations protect.
  prefs: []
  type: TYPE_NORMAL
- en: 'Non-control data attacks can range from very simple attacks targeting a single
    piece of data to very elaborate attacks with very high expressiveness [@Beer2021].
    A very simple example may look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The example shows a simplified[7](#fn7) function that reads a passphrase from
    a user, compares it with a known value and sets an integer stack variable to indicate
    whether “authentication” was successful or not. The function contains a very obvious
    buffer overflow, as the string length limit passed to `fgets` does not match the
    buffer size.
  prefs: []
  type: TYPE_NORMAL
- en: Figure @fig:non-control-data-attack shows the stack frame layout for this function
    when the code is compiled for AArch64 with Clang 10.0[8](#fn8). As the figure
    shows, an overflow of `passphrase` will overwrite `authenticated`, setting it
    to a non-zero value, even though the passphrase was incorrect. The `authenticate`
    function will then return a non-zero value, incorrectly indicating authentication
    success.
  prefs: []
  type: TYPE_NORMAL
- en: '![Stack frame for authenticate](../media/file5.svg)'
  prefs: []
  type: TYPE_IMG
- en: Stack frame for `authenticate`
  prefs: []
  type: TYPE_NORMAL
- en: 'For many more simple examples of data-only attacks that can occur in real applications,
    see [@Chen2005]. Although this makes it clear that data-only attacks are a real
    issue, it leaves open a very important question: what are the limits of such attacks?
    It is tempting to assume that data-only attacks are somehow inherently limited,
    however it has been demonstrated in [@Hu2016] that they can, in fact, be very
    expressive. [@Hu2016] describes Data-Oriented Programming (DOP), a general method
    for building data-only attacks against a vulnerable program, starting from a known
    memory error in the program[9](#fn9).'
  prefs: []
  type: TYPE_NORMAL
- en: The authors of [@Hu2016] describe a small language called MINDOP, with a virtual
    instruction set and virtual registers. The virtual registers of MINDOP correspond
    to memory locations. The MINDOP instructions correspond to operations on these
    virtual registers, for example loading a value into a virtual register, storing
    a value from a virtual register, arithmetic operations and even conditional and
    unconditional jumps. The authors show how to identify gadgets in the code that
    implement the various MINDOP instructions and are reachable from memory errors,
    and how those gadgets can be stitched together with the help of dispatcher gadgets,
    the role of which is specifically to chain gadgets together.
  prefs: []
  type: TYPE_NORMAL
- en: Stitching gadgets together is simpler for interactive attacks, where the attacker
    can keep providing malicious input to trigger the initial memory error and a certain
    chain of gadgets, as many times as needed. For non-interactive attacks, the MINDOP
    jump operations are required as well, used in conjunction with a memory location
    that provides a virtual program counter.
  prefs: []
  type: TYPE_NORMAL
- en: The process of creating a DOP attack is not so simple and not fully automated.
    Related literature [@Ispoglou2018] focuses on automating data-only attacks.
  prefs: []
  type: TYPE_NORMAL
- en: 'When reading write-ups on recent security issues, instead of terminology related
    to data-oriented gadgets, you are more likely to encounter the term “primitive”,
    which has been described in [an earlier section](ch002.xhtml#exploitation-primitives).
    These concepts are related: an arbitrary read primitive, for example, can be produced
    by chaining a (possibly large) number of DOP gadgets. Talking about primitives
    offers a nicer level of abstraction, as it tends to be simpler to reason in terms
    of higher-level operations instead of many small pieces of code that need to be
    stitched together to perform the operations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, data-only attacks are a significant concern. As most of the mitigation
    techniques we have seen so far are control-flow oriented, they are by design inadequate
    to protect against this different type of attacks. In the next section, we will
    look at what we can do to address them at their source: memory errors.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.8 Preventing and detecting memory errors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have so far discussed how languages that are [not memory safe](ch002.xhtml#a-bit-of-background-on-memory-vulnerabilities),
    like C and C++, are vulnerable to memory errors and therefore exploitation. In
    this section, we will discuss tools that are available to C/C++ programmers to
    help them detect vulnerabilities that can lead to memory errors.
  prefs: []
  type: TYPE_NORMAL
- en: 2.8.1 Sanitizers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Sanitizers are tools that detect bugs during program execution. Sanitizers
    usually have two components: a compiler instrumentation part that introduces the
    new checks, and a runtime library part. They are often too expensive to run in
    production mode, as they tend to increase execution time and memory usage. They
    are commonly used during testing of an application, frequently in combination
    with fuzzers[10](#fn10).'
  prefs: []
  type: TYPE_NORMAL
- en: A very popular sanitizer is [Address Sanitizer (ASan)](https://clang.llvm.org/docs/AddressSanitizer.html).
    It aims to detect various memory errors. These include out-of-bounds accesses,
    use-after-free, double-free and invalid free[11](#fn11). There are Address Sanitizer
    implementations for both GCC and Clang, but we will focus on the Clang implementation
    here.
  prefs: []
  type: TYPE_NORMAL
- en: ASan uses shadow memory to keep track of the state of the application’s memory.
    Each byte of shadow memory records information on 8 bytes of the application’s
    memory. It represents how many of the 8 bytes are addressable. When none of the
    bytes are addressable, it encodes additional details (whether the 8 bytes are
    out-of-bounds stack, out-of-bounds heap, freed memory, and so on). Requiring one
    byte of shadow memory for every 8 bytes of application memory means that ASan
    needs to reserve one-eighth of the application’s virtual address space [@Serebryany2012].
    Shadow memory is allocated in one contiguous chunk, which keeps mapping application
    memory to shadow memory simple.
  prefs: []
  type: TYPE_NORMAL
- en: ASan’s runtime library replaces memory allocation functions like `malloc` and
    `free` with its own specialized versions. `malloc` introduces redzones before
    and after each allocation, which are marked as unaddressable. `free` marks the
    entire allocation as unaddressable and places it in quarantine, so that it doesn’t
    get reallocated for a while (in a FIFO basis). This allows for detecting use-after-free.
    The runtime library also handles management of the shadow memory.
  prefs: []
  type: TYPE_NORMAL
- en: ASan’s code instrumentation in the compiler introduces redzones around each
    stack array allocation, and around globals. It then instruments loads and stores
    to check whether the accessed memory is addressable, based on the information
    stored in the shadow memory, and reports an error if unaddressable memory is accessed.
  prefs: []
  type: TYPE_NORMAL
- en: ASan doesn’t produce false positives and is easy to use. It requires compiling
    and linking a program with the `-fsanitize=address` option. It is used in practice
    for testing [large projects](https://chromium.googlesource.com/chromium/src/+/HEAD/docs/asan.md).
    There is a similar tool for dynamic memory error detection in the Linux kernel,
    [KASAN](https://www.kernel.org/doc/html/v5.0/dev-tools/kasan.html).
  prefs: []
  type: TYPE_NORMAL
- en: ASan’s biggest drawback is its high runtime overhead and memory usage, due to
    the quarantine, redzones and shadow memory. [Hardware-assisted AddressSanitizer
    (HWASAN)](https://clang.llvm.org/docs/HardwareAssistedAddressSanitizerDesign.html)
    works similarly to ASan, but with partial hardware assistance can result in lower
    memory overheads, at the cost of being less portable.
  prefs: []
  type: TYPE_NORMAL
- en: On AArch64, HWASAN uses Top-Byte Ignore (TBI). When TBI is enabled, the top
    byte of a pointer is ignored when performing a memory access, allowing software
    to use that top byte to store metadata, without affecting execution. Each allocation
    is aligned to 16 bytes and each 16-byte chunk of memory (called “granule”) is
    randomly assigned an 8-bit tag. The tag is stored in shadow memory and is also
    placed in the top byte of the pointer to the object. Memory loads and stores are
    then instrumented to check that the tag stored in the pointer matches the tag
    stored in memory, and report an error when a mismatch happens. Add diagram to
    demonstrate how HWASAN works [#168](https://github.com/llsoftsec/llsoftsecbook/issues/168)
  prefs: []
  type: TYPE_NORMAL
- en: For granules shorter than 16 bytes, the value stored in shadow memory is not
    the actual tag, but the length of the granule. The actual tag is stored at the
    last byte of the granule itself. For tags in shadow memory with values between
    1 and 15, HWASAN checks that the access is within the bounds of the granule and
    the pointer tag matches the tag stored at the last byte of the granule.
  prefs: []
  type: TYPE_NORMAL
- en: HWASAN is also easy to use, and simply requires compiling and linking an application
    with the `-fsanitize=hwaddress` flag.
  prefs: []
  type: TYPE_NORMAL
- en: '[MemTagSanitizer](https://llvm.org/docs/MemTagSanitizer.html) goes one step
    further and uses the Armv8.5-A [Memory Tagging Extension (MTE)](https://developer.arm.com/documentation/102925/0100).
    With MTE, the tag checking is done automatically by hardware, and an exception
    is raised on mismatch. MTE’s granule size is 16 bits, whereas tags are 4-bit.
    Consider adding a whole section on MTE and its applications [#169](https://github.com/llsoftsec/llsoftsecbook/issues/169)'
  prefs: []
  type: TYPE_NORMAL
- en: '[UndefinedBehaviorSanitizer (UBSan)](https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html#ubsan-checks)
    detects undefined behavior during program execution, for example array out-of-bounds
    accesses for statically determined array bounds, null pointer dereference, signed
    integer overflow and various kinds of integer conversions that result in data
    loss. Although some of these checks are not directly related to memory errors,
    these kinds of errors can lead to incorrect pointer arithmetic, incorrect allocation
    sizes, and other issues that lead to memory errors, so it is important to detect
    them and address them.'
  prefs: []
  type: TYPE_NORMAL
- en: UBSan’s documentation describes the full list of available checks. The majority
    of these checks are enabled with the `-fsanitize=undefined` flag, but there are
    also other useful groupings of checks, for example `-fsanitize=integer` for checks
    related to integer conversions and arithmetic.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many other sanitizers, more than can reasonably be covered in this
    section. For the interested reader, we list a few more:'
  prefs: []
  type: TYPE_NORMAL
- en: '[MemorySanitizer](https://clang.llvm.org/docs/MemorySanitizer.html): detects
    uninitialized reads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ThreadSanitizer](https://clang.llvm.org/docs/ThreadSanitizer.html): detects
    data races.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GWP-ASan](https://llvm.org/docs/GwpAsan.html): detects use-after-free and
    heap buffer overflows, with low overhead that makes it suitable for production
    environments. It performs checks only on a sample of allocations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Describe other mechanisms for detecting memory errors, both software-based (static
    analysis, library and buffer hardening) and hardware-based, e.g. PAuth-based pointer
    integrity schemes, MTE etc [#170](https://github.com/llsoftsec/llsoftsecbook/issues/170)
  prefs: []
  type: TYPE_NORMAL
- en: 2.8.2 Bounds checking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Making sure that memory accesses happen within the bounds of each object’s allocation
    is a very important part of memory safety. This is usually described with the
    term “spatial memory safety”. Out-of-bounds accesses result in restricted read/write
    primitives[12](#fn12). An attacker can often easily convert these into arbitrary
    read/write primitives. For example, this can be achieved by overwriting pointer
    fields in allocations following the object that was the target of the problematic
    memory access.
  prefs: []
  type: TYPE_NORMAL
- en: The C and C++ memory languages do not, as a general rule, perform bounds checking[13](#fn13).
    This is one of the sources of memory errors in C/C++ programs. However, compilers
    have a history of introducing bounds checks, even though the language does not
    require them, in an effort to improve security of existing C/C++ codebases.
  prefs: []
  type: TYPE_NORMAL
- en: One of the simplest compiler options is `-Warray-bounds`, which warns when an
    array access is always out of bounds. This is therefore restricted to arrays with
    statically known size. This option is supported by both GCC and Clang.
  prefs: []
  type: TYPE_NORMAL
- en: Another option supported by both compilers is `-fsanitize=bounds`, included
    in [UBSan](ch002.xhtml#sanitizers), which checks the bounds for accesses to statically
    sized arrays at runtime. This handles more cases than `-Warray-bounds`, as it
    can also check accesses to dynamic indices. However, it’s still limited, as it
    cannot perform bounds checks on dynamically sized arrays, and it is still restricted
    to array bounds checking. A more comprehensive solution would also cover pointers
    in general, especially if pointer arithmetic is performed.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may notice that there is a bit of overlap between the bounds checks introduced
    by `-fsanitize=bounds` and the Address Sanitizer. Although the scope of `-fsanitize=bounds`
    is restricted to statically sized arrays, it’s interesting to note that it can
    still catch intra-object overflows on array member accesses that the Address Sanitizer
    would not, because the access is still technically within the allocation. For
    example, given the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: a call to `get(f, 6)` will give an error with `-fsanitize=bounds`, but not with
    `-fsanitize=address`.
  prefs: []
  type: TYPE_NORMAL
- en: Clang and GCC also support two builtin functions that return information on
    the size of a variable. `__builtin_object_size` can be used for objects of statically
    known size and always evaluates at compile time, whereas `__builtin_dynamic_object_size`
    can also propagate dynamic information from allocation functions that have been
    marked with the [`alloc_size` function attribute](https://gcc.gnu.org/onlinedocs/gcc-4.7.2/gcc/Function-Attributes.html).
    These two builtins can be then used to introduce bounds checks in user or library
    code. For example, the [`_FORTIFY_SOURCE` macro](https://man7.org/linux/man-pages/man7/feature_test_macros.7.html)
    instructs `glibc` to introduce bounds checks in various string and memory manipulation
    functions, such as `memcpy`. The number of checks increases as the value of the
    macro increases (the used values are currently 1-3). For example, the lower two
    levels won’t use the `__builtin_dynamic_object_size` builtin, as it has a runtime
    overhead, additional to that of the checks themselves.
  prefs: []
  type: TYPE_NORMAL
- en: In order to support bounds checking for dynamically sized arrays, a recent proposal
    for [GCC](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=108896) and [Clang](https://reviews.llvm.org/D148381)
    proposes the addition of a struct member attribute, `element_count`. This attribute
    will apply to [flexible array members](https://en.wikipedia.org/wiki/Flexible_array_member)
    in structs, indicating another member of the struct that expresses the array’s
    length.
  prefs: []
  type: TYPE_NORMAL
- en: The [`-fbounds-safety`](https://discourse.llvm.org/t/rfc-enforcing-bounds-safety-in-c-fbounds-safety/70854)
    proposal goes a bit further, introducing a similar annotation that can be applied
    to pointers more generally. The proposal also aims to reduce the annotation burden
    placed on programmers by only requiring the annotations at [Application Binary
    Interface (ABI)](https://en.wikipedia.org/wiki/Application_binary_interface) boundaries[14](#fn14).
    Local variables which do not cross ABI boundaries are implicitly converted to
    use wide pointers. These wide pointers store bounds information alongside the
    original pointer.
  prefs: []
  type: TYPE_NORMAL
- en: There are also hardening efforts focusing on C++ codebases. For example, the
    [libc++ hardening modes](https://libcxx.llvm.org/Hardening.html) enable a number
    of assertions that aim to catch undefined behaviour in the library. The [C++ Buffer
    Hardening proposal](https://discourse.llvm.org/t/rfc-c-buffer-hardening/65734)
    aims to extend this library hardening. The proposal will also introduce a programming
    model in which all pointer arithmetic is considered unsafe. Pointer arithmetic
    will have to be replaced with alternatives from the C++ library, for example `std::array`.
    The implementation of these alternatives in the hardened library will include
    bounds checks.
  prefs: []
  type: TYPE_NORMAL
- en: Successfully using bounds checking compiler features for a large codebase requires
    substantial effort. An example of this is refactoring the Linux kernel to use
    bounds checks for flexible arrays, as described in [@Cook2023].
  prefs: []
  type: TYPE_NORMAL
- en: There are also hardware-based mitigations for violations of spatial memory safety.
    For example, [CHERI](https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/)
    introduces *capabilities* to conventional Instruction Set Architectures. Capabilities
    combine a virtual address with metadata that describes its corresponding bounds
    and permissions. Capabilities cannot be forged, and can thus provide very strong
    guarantees. Arm has developed a prototype architecture that adapts CHERI, as well
    as a prototype SoC and development board, as part of the [Arm Morello Program](https://www.arm.com/architecture/cpu/morello).
  prefs: []
  type: TYPE_NORMAL
- en: Of course, another approach to mitigating spatial memory safety vulnerabilities
    is using a language that has been designed with spatial memory safety in mind.
    Such languages make sure that all memory accesses are checked, either at compile-time
    or runtime. For example, the [Rust programming language](https://www.rust-lang.org/)
    introduces bounds checks whenever the compiler cannot prove that an access is
    within bounds[15](#fn15). There are many other memory safe languages, with different
    characteristics. One example is JavaScript, a dynamically typed, usually [JIT-compiled](#jit-compiler-vulnerabilities)
    language. We’ll discuss some of the issues that arise when implementing support
    for such a language in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 2.9 JIT compiler vulnerabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Compiler correctness is obviously very important, as miscompilation creates
    buggy programs even when the source code has no bugs. What might be less obvious
    is that these bugs can have security implications. For example, they can introduce
    memory safety errors in languages that are otherwise memory safe. In some cases,
    a bug might leave most programs unaffected and not cause security issues in practice
    before it is detected and fixed. This is, of course, assuming that the bug has
    not been [intentionally injected in the compiler](ch004.xhtml#supply-chain-attacks).
  prefs: []
  type: TYPE_NORMAL
- en: Compiler bugs are an interesting source of security issues for [just-in-time
    (JIT)](https://en.wikipedia.org/wiki/Just-in-time_compilation) compilers[16](#fn16).
    JIT compilation is often used in programs that receive source code as input during
    program execution, for example in web browsers, for executing JavaScript code
    included in web pages. In this context, the input to the JIT compiler comes from
    arbitrary websites and is therefore untrusted. Bugs in such JIT compilers can
    lead to compromise of the whole program (here, the browser) if a malicious input
    (e.g. coming from a malicious website) deliberately triggers miscompilation in
    order to break memory safety of the language being implemented.
  prefs: []
  type: TYPE_NORMAL
- en: For this section, we focus on JavaScript, which is a dynamically typed, memory
    safe language, but the concerns we discuss also apply to other languages that
    are compiled dynamically.
  prefs: []
  type: TYPE_NORMAL
- en: Without statically known types, in order to optimize JavaScript code, JavaScript
    engines resort to type profiling [@Pizlo2020], recording the types encountered
    while executing code. These types are then used during optimization, which speculates
    that the same types will be encountered in future runs of the code, and inserts
    checks to validate that these assumptions about types still hold. When a check
    fails, the optimized code is replaced by unoptimized code that can handle all
    types, a process known as deoptimization or on-stack replacement (OSR). Deoptimization
    makes sure that the state of the deoptimized function is recreated correctly for
    the point of execution where the type check failed.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, a function such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'will return a number when `x` and `y` are numbers, but a string when either
    is a string. An optimizing compiler can use the results of profiling to generate
    optimized code. For example, when both arguments are integers during profiling,
    it can generate code that looks like this in pseudocode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: You may be wondering how the type checks are implemented, and this is closely
    related to the representation of values in a JavaScript engine [@Wingo2011]. In
    short, JavaScript engines use specific bit patterns to indicate whether a value
    should be interpreted as a pointer, or as an integer or floating-point value.
    For example, the [V8 JavaScript engine](https://v8.dev/) uses the least significant
    bit to denote that a [value is a pointer](https://v8.dev/blog/pointer-compression#value-tagging-in-v8),
    otherwise it is a small integer (which needs to be shifted down to access its
    value). Pointers then point to objects that contain a [hidden class](https://v8.dev/docs/hidden-classes)
    member which is used for type checking.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the values for which typing information is gathered during profiling,
    optimizing JavaScript compilers propagate the profiled types to dependent values.
    For example if a value `x` is expected to be a string, and we check this assumption,
    then `x + 1` will also be a string (and no additional check is needed in this
    case). In addition to simple type propagation, they usually perform range analysis
    to determine as precise a range for a value as possible, which is useful for bounds
    check elimination.
  prefs: []
  type: TYPE_NORMAL
- en: Bounds check elimination (BCE) is a common optimization in languages that perform
    bounds checks on array accesses to ensure every accessed index is within the bounds
    of the array. BCE gets rid of bounds checks when they are proven to be redundant,
    e.g. when the array access uses a constant index that’s known to be smaller than
    the length of the array. See [here](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/length)
    for details on how out-of-bounds array accesses behave in JavaScript.
  prefs: []
  type: TYPE_NORMAL
- en: 'Range analysis is a good example of an analysis where a JIT compiler bug can
    introduce a vulnerability. Incorrect range analysis results can be used by bounds
    check elimination to incorrectly eliminate bounds checks that should actually
    have been maintained in the optimized code. For example, for the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: If range analysis decides that the value of `y` is in the range `[0, 2]`, but
    in reality the value is in the range `[0, 3]`, the bounds check for the access
    `a[y]` can be eliminated incorrectly, assuming the access is in-bounds. [@Glazunov2021]
    lists a few examples of similar hypothetical vulnerabilities, along with examples
    of vulnerabilities of this type that affected widely-used JavaScript engines.
  prefs: []
  type: TYPE_NORMAL
- en: The type of bug described above provides an attacker with a limited read or
    write primitive, as a linear overflow of the array allocation occurs. The attacker
    can then build on this primitive to get to an arbitrary read/write primitive.
    As JIT compilers generate executable code at runtime, they often use memory that
    is writable and executable at the same time. Such memory is very useful to attackers,
    who can use an arbitrary write primitive to copy their payload into this code
    memory, and then jump to it. Writable and executable memory, therefore, makes
    JITs lucrative targets for attackers.
  prefs: []
  type: TYPE_NORMAL
- en: Bugs related to range analysis are just one of the common types of bugs encountered
    in a JavaScript engine. [@Groß2022] lists some other common types of bugs that
    result in violations of temporal and spatial memory safety, as well as type safety,
    in JavaScript engines.
  prefs: []
  type: TYPE_NORMAL
- en: 'How can we defend against such vulnerabilities? There are several complementary
    approaches, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: Use fuzzing to discover compiler bugs. For JavaScript, a useful fuzzing tool
    is [Fuzzilli](https://github.com/googleprojectzero/fuzzilli).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Be more conservative when it comes to error-prone compiler optimizations such
    as bounds check elimination. For example, the [V8 JavaScript engine](https://v8.dev/)
    has introduced [hardening of bounds checks against typer bugs](https://bugs.chromium.org/p/v8/issues/detail?id=8806)
    [17](#fn17).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Instead of trying to prevent compiler (and other) bugs, assume they will be
    present and introduce mitigations that prevent attackers from building arbitrary
    read/write primitives on top of the initial limited primitives that bugs provide.
    For example, for 64-bit architectures, V8 implements a [sandbox](https://docs.google.com/document/d/1FM4fQmIhEqPG8uGp5o9A-mnPB5BOeScZYpkHjo0KKA8/edit),
    built on top of [pointer compression](https://v8.dev/blog/pointer-compression).
    With pointer compression, pointers are represented by 32-bit indices off a base
    pointer instead of as full 64-bit values. By making sure that all pointers inside
    the sandbox (where the JavaScript heap is located) are compressed, and that compressed
    pointers always point inside the sandbox, a limited primitive that allows overwriting
    memory within the sandbox cannot be used to build an arbitrary read/write primitive
    by overwriting pointer values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Preventing code memory from being executable and writable at the same time is
    also desirable. This is known as [W^X](https://en.wikipedia.org/wiki/W%5EX). A
    naive implementation of W^X that simply switches memory permissions based on page
    tables temporarily is not enough to prevent attackers from writing to code memory
    [@Song2015], when multiple threads are involved. A more effective solution would
    use a separate compilation process, which is the only process that has write access
    to the JIT’s code memory. Alternatively, some architectures provide special features
    that can restrict page-based memory permissions from userspace, effectively allowing
    permissions to be different for different threads. Such features can also be of
    use in implementing W^X. For AArch64, this feature is called [permission overlays](https://developer.arm.com/documentation/102376/0200/Permission-indirection-and-permission-overlay-extensions).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this section, we have discussed JIT compiler security and described JavaScript
    compiler bugs that lead to vulnerabilities. Although we haven’t focused on the
    details of JavaScript exploitation, an interested reader could take a look at
    [@saelo2021a] and [@saelo2021b].
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
