["```py\nfrom [bookutils](https://github.com/uds-se/fuzzingbook//tree/master/notebooks/shared/bookutils) import YouTubeVideo\nYouTubeVideo('k39i9de0L54') \n```", "```py\n>>> from [fuzzingbook.Parser](Parser.html) import <identifier> \n```", "```py\n>>> from [Grammars](Grammars.html) import US_PHONE_GRAMMAR\n>>> us_phone_parser = EarleyParser(US_PHONE_GRAMMAR) \n```", "```py\n>>> trees = us_phone_parser.parse(\"(555)987-6543\")\n>>> tree = list(trees)[0]\n>>> display_tree(tree) \n```", "```py\nimport [bookutils.setup](https://github.com/uds-se/fuzzingbook//tree/master/notebooks/shared/bookutils) \n```", "```py\nfrom [typing](https://docs.python.org/3/library/typing.html) import Dict, List, Tuple, Collection, Set, Iterable, Generator, cast \n```", "```py\nfrom [Fuzzer](Fuzzer.html) import Fuzzer  # minor dependency \n```", "```py\nfrom [Grammars](Grammars.html) import EXPR_GRAMMAR, START_SYMBOL, RE_NONTERMINAL\nfrom [Grammars](Grammars.html) import is_valid_grammar, syntax_diagram, Grammar \n```", "```py\nfrom [GrammarFuzzer](GrammarFuzzer.html) import GrammarFuzzer, display_tree, tree_to_string, dot_escape\nfrom [GrammarFuzzer](GrammarFuzzer.html) import DerivationTree \n```", "```py\nfrom [ExpectError](ExpectError.html) import ExpectError \n```", "```py\nfrom [IPython.display](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html) import display \n```", "```py\nfrom [Timer](Timer.html) import Timer \n```", "```py\ndef process_inventory(inventory):\n    res = []\n    for vehicle in inventory.split('\\n'):\n        ret = process_vehicle(vehicle)\n        res.extend(ret)\n    return '\\n'.join(res) \n```", "```py\ndef process_vehicle(vehicle):\n    year, kind, company, model, *_ = vehicle.split(',')\n    if kind == 'van':\n        return process_van(year, company, model)\n\n    elif kind == 'car':\n        return process_car(year, company, model)\n\n    else:\n        raise Exception('Invalid entry') \n```", "```py\ndef process_van(year, company, model):\n    res = [\"We have a %s  %s van from %s vintage.\" % (company, model, year)]\n    iyear = int(year)\n    if iyear > 2010:\n        res.append(\"It is a recent model!\")\n    else:\n        res.append(\"It is an old but reliable model!\")\n    return res \n```", "```py\ndef process_car(year, company, model):\n    res = [\"We have a %s  %s car from %s vintage.\" % (company, model, year)]\n    iyear = int(year)\n    if iyear > 2016:\n        res.append(\"It is a recent model!\")\n    else:\n        res.append(\"It is an old but reliable model!\")\n    return res \n```", "```py\nmystring = \"\"\"\\\n1997,van,Ford,E350\n2000,car,Mercury,Cougar\\\n\"\"\"\nprint(process_inventory(mystring)) \n```", "```py\nWe have a Ford E350 van from 1997 vintage.\nIt is an old but reliable model!\nWe have a Mercury Cougar car from 2000 vintage.\nIt is an old but reliable model!\n\n```", "```py\nimport [string](https://docs.python.org/3/library/string.html) \n```", "```py\nCSV_GRAMMAR: Grammar = {\n    '<start>': ['<csvline>'],\n    '<csvline>': ['<items>'],\n    '<items>': ['<item>,<items>', '<item>'],\n    '<item>': ['<letters>'],\n    '<letters>': ['<letter><letters>', '<letter>'],\n    '<letter>': list(string.ascii_letters + string.digits + string.punctuation + ' \\t\\n')\n} \n```", "```py\nsyntax_diagram(CSV_GRAMMAR) \n```", "```py\nstart\n\n```", "```py\ncsvline\n\n```", "```py\nitems\n\n```", "```py\nitem\n\n```", "```py\nletters\n\n```", "```py\nletter\n\n```", "```py\ngf = GrammarFuzzer(CSV_GRAMMAR, min_nonterminals=4)\ntrials = 1000\nvalid: List[str] = []\ntime = 0\nfor i in range(trials):\n    with Timer() as t:\n        vehicle_info = gf.fuzz()\n        try:\n            process_vehicle(vehicle_info)\n            valid.append(vehicle_info)\n        except:\n            pass\n        time += t.elapsed_time()\nprint(\"%d valid strings, that is GrammarFuzzer generated %f%% valid entries from %d inputs\" %\n      (len(valid), len(valid) * 100.0 / trials, trials))\nprint(\"Total time of %f seconds\" % time) \n```", "```py\n0 valid strings, that is GrammarFuzzer generated 0.000000% valid entries from 1000 inputs\nTotal time of 2.478398 seconds\n\n```", "```py\ngf = GrammarFuzzer(CSV_GRAMMAR, min_nonterminals=4)\ntrials = 10\ntime = 0\nfor i in range(trials):\n    vehicle_info = gf.fuzz()\n    try:\n        print(repr(vehicle_info), end=\"\")\n        process_vehicle(vehicle_info)\n    except Exception as e:\n        print(\"\\t\", e)\n    else:\n        print() \n```", "```py\n'9w9J\\'/,LU<\"l,|,Y,Zv)Amvx,c\\n'\t Invalid entry\n'(n8].H7,qolS'\t not enough values to unpack (expected at least 4, got 2)\n'\\nQoLWQ,jSa'\t not enough values to unpack (expected at least 4, got 2)\n'K1,\\n,RE,fq,%,,sT+aAb'\t Invalid entry\n\"m,d,,8j4'),-yQ,B7\"\t Invalid entry\n'g4,s1\\t[}{.,M,<,\\nzd,.am'\t Invalid entry\n',Z[,z,c,#x1,gc.F'\t Invalid entry\n'pWs,rT`,R'\t not enough values to unpack (expected at least 4, got 3)\n'iN,br%,Q,R'\t Invalid entry\n'ol,\\nH<\\tn,^#,=A'\t Invalid entry\n\n```", "```py\nimport [copy](https://docs.python.org/3/library/copy.html) \n```", "```py\nimport [random](https://docs.python.org/3/library/random.html) \n```", "```py\nclass PooledGrammarFuzzer(GrammarFuzzer):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._node_cache = {}\n\n    def update_cache(self, key, values):\n        self._node_cache[key] = values\n\n    def expand_node_randomly(self, node):\n        (symbol, children) = node\n        assert children is None\n        if symbol in self._node_cache:\n            if random.randint(0, 1) == 1:\n                return super().expand_node_randomly(node)\n            return copy.deepcopy(random.choice(self._node_cache[symbol]))\n        return super().expand_node_randomly(node) \n```", "```py\ngf = PooledGrammarFuzzer(CSV_GRAMMAR, min_nonterminals=4)\ngf.update_cache('<item>', [\n    ('<item>', [('car', [])]),\n    ('<item>', [('van', [])]),\n])\ntrials = 10\ntime = 0\nfor i in range(trials):\n    vehicle_info = gf.fuzz()\n    try:\n        print(repr(vehicle_info), end=\"\")\n        process_vehicle(vehicle_info)\n    except Exception as e:\n        print(\"\\t\", e)\n    else:\n        print() \n```", "```py\n',h,van,|'\t Invalid entry\n'M,w:K,car,car,van'\t Invalid entry\n'J,?Y,van,van,car,J,~D+'\t Invalid entry\n'S4,car,car,o'\t invalid literal for int() with base 10: 'S4'\n'2*-,van'\t not enough values to unpack (expected at least 4, got 2)\n'van,%,5,]'\t Invalid entry\n'van,G3{y,j,h:'\t Invalid entry\n'$0;o,M,car,car'\t Invalid entry\n'2d,f,e'\t not enough values to unpack (expected at least 4, got 3)\n'/~NE,car,car'\t not enough values to unpack (expected at least 4, got 3)\n\n```", "```py\n    parser = Parser(grammar)\n    ```", "```py\ntrees = parser.parse(input) \n```", "```py\ndef simple_parse_csv(mystring: str) -> DerivationTree:\n    children: List[DerivationTree] = []\n    tree = (START_SYMBOL, children)\n    for i, line in enumerate(mystring.split('\\n')):\n        children.append((\"record %d\" % i, [(cell, [])\n                                           for cell in line.split(',')]))\n    return tree \n```", "```py\ndef lr_graph(dot):\n    dot.attr('node', shape='plain')\n    dot.graph_attr['rankdir'] = 'LR' \n```", "```py\ntree = simple_parse_csv(mystring)\ndisplay_tree(tree, graph_attr=lr_graph) \n```", "```py\nmystring = '''\\\n1997,Ford,E350,\"ac, abs, moon\",3000.00\\\n'''\nprint(mystring) \n```", "```py\n1997,Ford,E350,\"ac, abs, moon\",3000.00\n\n```", "```py\ndef highlight_node(predicate):\n    def hl_node(dot, nid, symbol, ann):\n        if predicate(dot, nid, symbol, ann):\n            dot.node(repr(nid), dot_escape(symbol), fontcolor='red')\n        else:\n            dot.node(repr(nid), dot_escape(symbol))\n    return hl_node \n```", "```py\ntree = simple_parse_csv(mystring)\nbad_nodes = {5, 6, 7, 12, 13, 20, 22, 23, 24, 25} \n```", "```py\ndef hl_predicate(_d, nid, _s, _a): return nid in bad_nodes \n```", "```py\nhighlight_err_node = highlight_node(hl_predicate)\ndisplay_tree(tree, log=False, node_attr=highlight_err_node,\n             graph_attr=lr_graph) \n```", "```py\ndef parse_quote(string, i):\n    v = string[i + 1:].find('\"')\n    return v + i + 1 if v >= 0 else -1 \n```", "```py\ndef find_comma(string, i):\n    slen = len(string)\n    while i < slen:\n        if string[i] == '\"':\n            i = parse_quote(string, i)\n            if i == -1:\n                return -1\n        if string[i] == ',':\n            return i\n        i += 1\n    return -1 \n```", "```py\ndef comma_split(string):\n    slen = len(string)\n    i = 0\n    while i < slen:\n        c = find_comma(string, i)\n        if c == -1:\n            yield string[i:]\n            return\n        else:\n            yield string[i:c]\n        i = c + 1 \n```", "```py\ndef parse_csv(mystring):\n    children = []\n    tree = (START_SYMBOL, children)\n    for i, line in enumerate(mystring.split('\\n')):\n        children.append((\"record %d\" % i, [(cell, [])\n                                           for cell in comma_split(line)]))\n    return tree \n```", "```py\ntree = parse_csv(mystring)\ndisplay_tree(tree, graph_attr=lr_graph) \n```", "```py\nmystring = '''\\\n1999,Chevy,\"Venture \\\\\"Extended Edition, Very Large\\\\\"\",,5000.00\\\n'''\nprint(mystring) \n```", "```py\n1999,Chevy,\"Venture \\\"Extended Edition, Very Large\\\"\",,5000.00\n\n```", "```py\ntree = parse_csv(mystring)\nbad_nodes = {4, 5}\ndisplay_tree(tree, node_attr=highlight_err_node, graph_attr=lr_graph) \n```", "```py\nmystring = '''\\\n1996,Jeep,Grand Cherokee,\"MUST SELL!\nair, moon roof, loaded\",4799.00\n'''\nprint(mystring) \n```", "```py\n1996,Jeep,Grand Cherokee,\"MUST SELL!\nair, moon roof, loaded\",4799.00\n\n```", "```py\ntree = parse_csv(mystring)\nbad_nodes = {5, 6, 7, 8, 9, 10}\ndisplay_tree(tree, node_attr=highlight_err_node, graph_attr=lr_graph) \n```", "```py\nA1_GRAMMAR: Grammar = {\n    \"<start>\": [\"<expr>\"],\n    \"<expr>\": [\"<expr>+<expr>\", \"<expr>-<expr>\", \"<integer>\"],\n    \"<integer>\": [\"<digit><integer>\", \"<digit>\"],\n    \"<digit>\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n} \n```", "```py\nsyntax_diagram(A1_GRAMMAR) \n```", "```py\nstart\n\n```", "```py\nexpr\n\n```", "```py\ninteger\n\n```", "```py\ndigit\n\n```", "```py\nmystring = '1+2' \n```", "```py\ntree = ('<start>', [('<expr>',\n                     [('<expr>', [('<integer>', [('<digit>', [('1', [])])])]),\n                      ('+', []),\n                      ('<expr>', [('<integer>', [('<digit>', [('2',\n                                                               [])])])])])])\nassert mystring == tree_to_string(tree)\ndisplay_tree(tree) \n```", "```py\nA2_GRAMMAR: Grammar = {\n    \"<start>\": [\"<expr>\"],\n    \"<expr>\": [\"<integer><expr_>\"],\n    \"<expr_>\": [\"+<expr>\", \"-<expr>\", \"\"],\n    \"<integer>\": [\"<digit><integer_>\"],\n    \"<integer_>\": [\"<integer>\", \"\"],\n    \"<digit>\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n} \n```", "```py\nsyntax_diagram(A2_GRAMMAR) \n```", "```py\nstart\n\n```", "```py\nexpr\n\n```", "```py\nexpr_\n\n```", "```py\ninteger\n\n```", "```py\ninteger_\n\n```", "```py\ndigit\n\n```", "```py\ntree = ('<start>', [('<expr>', [('<integer>', [('<digit>', [('1', [])]),\n                                               ('<integer_>', [])]),\n                                ('<expr_>', [('+', []),\n                                             ('<expr>',\n                                              [('<integer>',\n                                                [('<digit>', [('2', [])]),\n                                                 ('<integer_>', [])]),\n                                               ('<expr_>', [])])])])])\nassert mystring == tree_to_string(tree)\ndisplay_tree(tree) \n```", "```py\nLR_GRAMMAR: Grammar = {\n    '<start>': ['<A>'],\n    '<A>': ['<A>a', ''],\n} \n```", "```py\nsyntax_diagram(LR_GRAMMAR) \n```", "```py\nstart\n\n```", "```py\nA\n\n```", "```py\nmystring = 'aaaaaa'\ndisplay_tree(\n    ('<start>', [('<A>', [('<A>', [('<A>', []), ('a', [])]), ('a', [])]),\n                 ('a', [])])) \n```", "```py\nRR_GRAMMAR: Grammar = {\n    '<start>': ['<A>'],\n    '<A>': ['a<A>', ''],\n} \n```", "```py\nsyntax_diagram(RR_GRAMMAR) \n```", "```py\nstart\n\n```", "```py\nA\n\n```", "```py\ndisplay_tree(('<start>', [('<A>', [\n                  ('a', []), ('<A>', [('a', []), ('<A>', [('a', []), ('<A>', [])])])])]\n             )) \n```", "```py\nmystring = '1+2+3'\ntree = ('<start>',\n        [('<expr>',\n          [('<expr>', [('<expr>', [('<integer>', [('<digit>', [('1', [])])])]),\n                       ('+', []),\n                       ('<expr>', [('<integer>',\n                                    [('<digit>', [('2', [])])])])]), ('+', []),\n           ('<expr>', [('<integer>', [('<digit>', [('3', [])])])])])])\nassert mystring == tree_to_string(tree)\ndisplay_tree(tree) \n```", "```py\ntree = ('<start>',\n        [('<expr>', [('<expr>', [('<integer>', [('<digit>', [('1', [])])])]),\n                     ('+', []),\n                     ('<expr>',\n                      [('<expr>', [('<integer>', [('<digit>', [('2', [])])])]),\n                       ('+', []),\n                       ('<expr>', [('<integer>', [('<digit>', [('3',\n                                                                [])])])])])])])\nassert tree_to_string(tree) == mystring\ndisplay_tree(tree) \n```", "```py\nclass Parser:\n  \"\"\"Base class for parsing.\"\"\"\n\n    def __init__(self, grammar: Grammar, *,\n                 start_symbol: str = START_SYMBOL,\n                 log: bool = False,\n                 coalesce: bool = True,\n                 tokens: Set[str] = set()) -> None:\n  \"\"\"Constructor.\n `grammar` is the grammar to be used for parsing.\n Keyword arguments:\n `start_symbol` is the start symbol (default: '<start>').\n `log` enables logging (default: False).\n `coalesce` defines if tokens should be coalesced (default: True).\n `tokens`, if set, is a set of tokens to be used.\"\"\"\n        self._grammar = grammar\n        self._start_symbol = start_symbol\n        self.log = log\n        self.coalesce_tokens = coalesce\n        self.tokens = tokens\n\n    def grammar(self) -> Grammar:\n  \"\"\"Return the grammar of this parser.\"\"\"\n        return self._grammar\n\n    def start_symbol(self) -> str:\n  \"\"\"Return the start symbol of this parser.\"\"\"\n        return self._start_symbol\n\n    def parse_prefix(self, text: str) -> Tuple[int, Iterable[DerivationTree]]:\n  \"\"\"Return pair (cursor, forest) for longest prefix of text. \n To be defined in subclasses.\"\"\"\n        raise NotImplementedError\n\n    def parse(self, text: str) -> Iterable[DerivationTree]:\n  \"\"\"Parse `text` using the grammar. \n Return an iterable of parse trees.\"\"\"\n        cursor, forest = self.parse_prefix(text)\n        if cursor < len(text):\n            raise SyntaxError(\"at \" + repr(text[cursor:]))\n        return [self.prune_tree(tree) for tree in forest]\n\n    def parse_on(self, text: str, start_symbol: str) -> Generator:\n        old_start = self._start_symbol\n        try:\n            self._start_symbol = start_symbol\n            yield from self.parse(text)\n        finally:\n            self._start_symbol = old_start\n\n    def coalesce(self, children: List[DerivationTree]) -> List[DerivationTree]:\n        last = ''\n        new_lst: List[DerivationTree] = []\n        for cn, cc in children:\n            if cn not in self._grammar:\n                last += cn\n            else:\n                if last:\n                    new_lst.append((last, []))\n                    last = ''\n                new_lst.append((cn, cc))\n        if last:\n            new_lst.append((last, []))\n        return new_lst\n\n    def prune_tree(self, tree: DerivationTree) -> DerivationTree:\n        name, children = tree\n        assert isinstance(children, list)\n\n        if self.coalesce_tokens:\n            children = self.coalesce(cast(List[DerivationTree], children))\n        if name in self.tokens:\n            return (name, [(tree_to_string(tree), [])])\n        else:\n            return (name, [self.prune_tree(c) for c in children]) \n```", "```py\nCanonicalGrammar = Dict[str, List[List[str]]] \n```", "```py\nimport [re](https://docs.python.org/3/library/re.html) \n```", "```py\ndef single_char_tokens(grammar: Grammar) -> Dict[str, List[List[Collection[str]]]]:\n    g_ = {}\n    for key in grammar:\n        rules_ = []\n        for rule in grammar[key]:\n            rule_ = []\n            for token in rule:\n                if token in grammar:\n                    rule_.append(token)\n                else:\n                    rule_.extend(token)\n            rules_.append(rule_)\n        g_[key] = rules_\n    return g_ \n```", "```py\ndef canonical(grammar: Grammar) -> CanonicalGrammar:\n    def split(expansion):\n        if isinstance(expansion, tuple):\n            expansion = expansion[0]\n\n        return [token for token in re.split(\n            RE_NONTERMINAL, expansion) if token]\n\n    return {\n        k: [split(expression) for expression in alternatives]\n        for k, alternatives in grammar.items()\n    } \n```", "```py\nCE_GRAMMAR: CanonicalGrammar = canonical(EXPR_GRAMMAR)\nCE_GRAMMAR \n```", "```py\n{'<start>': [['<expr>']],\n '<expr>': [['<term>', ' + ', '<expr>'],\n  ['<term>', ' - ', '<expr>'],\n  ['<term>']],\n '<term>': [['<factor>', ' * ', '<term>'],\n  ['<factor>', ' / ', '<term>'],\n  ['<factor>']],\n '<factor>': [['+', '<factor>'],\n  ['-', '<factor>'],\n  ['(', '<expr>', ')'],\n  ['<integer>', '.', '<integer>'],\n  ['<integer>']],\n '<integer>': [['<digit>', '<integer>'], ['<digit>']],\n '<digit>': [['0'],\n  ['1'],\n  ['2'],\n  ['3'],\n  ['4'],\n  ['5'],\n  ['6'],\n  ['7'],\n  ['8'],\n  ['9']]}\n\n```", "```py\ndef recurse_grammar(grammar, key, order):\n    rules = sorted(grammar[key])\n    old_len = len(order)\n    for rule in rules:\n        for token in rule:\n            if token not in grammar: continue\n            if token not in order:\n                order.append(token)\n    new = order[old_len:]\n    for ckey in new:\n        recurse_grammar(grammar, ckey, order) \n```", "```py\ndef show_grammar(grammar, start_symbol=START_SYMBOL):\n    order = [start_symbol]\n    recurse_grammar(grammar, start_symbol, order)\n    return {k: sorted(grammar[k]) for k in order} \n```", "```py\nshow_grammar(CE_GRAMMAR) \n```", "```py\n{'<start>': [['<expr>']],\n '<expr>': [['<term>'],\n  ['<term>', ' + ', '<expr>'],\n  ['<term>', ' - ', '<expr>']],\n '<term>': [['<factor>'],\n  ['<factor>', ' * ', '<term>'],\n  ['<factor>', ' / ', '<term>']],\n '<factor>': [['(', '<expr>', ')'],\n  ['+', '<factor>'],\n  ['-', '<factor>'],\n  ['<integer>'],\n  ['<integer>', '.', '<integer>']],\n '<integer>': [['<digit>'], ['<digit>', '<integer>']],\n '<digit>': [['0'],\n  ['1'],\n  ['2'],\n  ['3'],\n  ['4'],\n  ['5'],\n  ['6'],\n  ['7'],\n  ['8'],\n  ['9']]}\n\n```", "```py\ndef non_canonical(grammar):\n    new_grammar = {}\n    for k in grammar:\n        rules = grammar[k]\n        new_rules = []\n        for rule in rules:\n            new_rules.append(''.join(rule))\n        new_grammar[k] = new_rules\n    return new_grammar \n```", "```py\nnon_canonical(CE_GRAMMAR) \n```", "```py\n{'<start>': ['<expr>'],\n '<expr>': ['<term> + <expr>', '<term> - <expr>', '<term>'],\n '<term>': ['<factor> * <term>', '<factor> / <term>', '<factor>'],\n '<factor>': ['+<factor>',\n  '-<factor>',\n  '(<expr>)',\n  '<integer>.<integer>',\n  '<integer>'],\n '<integer>': ['<digit><integer>', '<digit>'],\n '<digit>': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']}\n\n```", "```py\nclass Parser(Parser):\n    def __init__(self, grammar, **kwargs):\n        self._start_symbol = kwargs.get('start_symbol', START_SYMBOL)\n        self.log = kwargs.get('log', False)\n        self.tokens = kwargs.get('tokens', set())\n        self.coalesce_tokens = kwargs.get('coalesce', True)\n        canonical_grammar = kwargs.get('canonical', False)\n        if canonical_grammar:\n            self.cgrammar = single_char_tokens(grammar)\n            self._grammar = non_canonical(grammar)\n        else:\n            self._grammar = dict(grammar)\n            self.cgrammar = single_char_tokens(canonical(grammar))\n        # we do not require a single rule for the start symbol\n        if len(grammar.get(self._start_symbol, [])) != 1:\n            self.cgrammar['<>'] = [[self._start_symbol]] \n```", "```py\nclass Parser(Parser):\n    def prune_tree(self, tree):\n        name, children = tree\n        if name == '<>':\n            assert len(children) == 1\n            return self.prune_tree(children[0])\n        if self.coalesce_tokens:\n            children = self.coalesce(children)\n        if name in self.tokens:\n            return (name, [(tree_to_string(tree), [])])\n        else:\n            return (name, [self.prune_tree(c) for c in children]) \n```", "```py\nPEG1 = {\n    '<start>': ['a', 'b']\n} \n```", "```py\nPEG2 = {\n    '<start>': ['ab', 'abc']\n} \n```", "```py\nclass PEGParser(Parser):\n    def parse_prefix(self, text):\n        cursor, tree = self.unify_key(self.start_symbol(), text, 0)\n        return cursor, [tree] \n```", "```py\nclass PEGParser(PEGParser):\n  \"\"\"Packrat parser for Parsing Expression Grammars (PEGs).\"\"\"\n\n    def unify_key(self, key, text, at=0):\n        if self.log:\n            print(\"unify_key: %s with %s\" % (repr(key), repr(text[at:])))\n        if key not in self.cgrammar:\n            if text[at:].startswith(key):\n                return at + len(key), (key, [])\n            else:\n                return at, None\n        for rule in self.cgrammar[key]:\n            to, res = self.unify_rule(rule, text, at)\n            if res is not None:\n                return (to, (key, res))\n        return 0, None \n```", "```py\nmystring = \"1\"\npeg = PEGParser(EXPR_GRAMMAR, log=True)\npeg.unify_key('1', mystring) \n```", "```py\nunify_key: '1' with '1'\n\n```", "```py\n(1, ('1', []))\n\n```", "```py\nmystring = \"2\"\npeg.unify_key('1', mystring) \n```", "```py\nunify_key: '1' with '2'\n\n```", "```py\n(0, None)\n\n```", "```py\nclass PEGParser(PEGParser):\n    def unify_rule(self, rule, text, at):\n        if self.log:\n            print('unify_rule: %s with %s' % (repr(rule), repr(text[at:])))\n        results = []\n        for token in rule:\n            at, res = self.unify_key(token, text, at)\n            if res is None:\n                return at, None\n            results.append(res)\n        return at, results \n```", "```py\nmystring = \"0\"\npeg = PEGParser(EXPR_GRAMMAR, log=True)\npeg.unify_rule(peg.cgrammar['<digit>'][0], mystring, 0) \n```", "```py\nunify_rule: ['0'] with '0'\nunify_key: '0' with '0'\n\n```", "```py\n(1, [('0', [])])\n\n```", "```py\nmystring = \"12\"\npeg.unify_rule(peg.cgrammar['<integer>'][0], mystring, 0) \n```", "```py\nunify_rule: ['<digit>', '<integer>'] with '12'\nunify_key: '<digit>' with '12'\nunify_rule: ['0'] with '12'\nunify_key: '0' with '12'\nunify_rule: ['1'] with '12'\nunify_key: '1' with '12'\nunify_key: '<integer>' with '2'\nunify_rule: ['<digit>', '<integer>'] with '2'\nunify_key: '<digit>' with '2'\nunify_rule: ['0'] with '2'\nunify_key: '0' with '2'\nunify_rule: ['1'] with '2'\nunify_key: '1' with '2'\nunify_rule: ['2'] with '2'\nunify_key: '2' with '2'\nunify_key: '<integer>' with ''\nunify_rule: ['<digit>', '<integer>'] with ''\nunify_key: '<digit>' with ''\nunify_rule: ['0'] with ''\nunify_key: '0' with ''\nunify_rule: ['1'] with ''\nunify_key: '1' with ''\nunify_rule: ['2'] with ''\nunify_key: '2' with ''\nunify_rule: ['3'] with ''\nunify_key: '3' with ''\nunify_rule: ['4'] with ''\nunify_key: '4' with ''\nunify_rule: ['5'] with ''\nunify_key: '5' with ''\nunify_rule: ['6'] with ''\nunify_key: '6' with ''\nunify_rule: ['7'] with ''\nunify_key: '7' with ''\nunify_rule: ['8'] with ''\nunify_key: '8' with ''\nunify_rule: ['9'] with ''\nunify_key: '9' with ''\nunify_rule: ['<digit>'] with ''\nunify_key: '<digit>' with ''\nunify_rule: ['0'] with ''\nunify_key: '0' with ''\nunify_rule: ['1'] with ''\nunify_key: '1' with ''\nunify_rule: ['2'] with ''\nunify_key: '2' with ''\nunify_rule: ['3'] with ''\nunify_key: '3' with ''\nunify_rule: ['4'] with ''\nunify_key: '4' with ''\nunify_rule: ['5'] with ''\nunify_key: '5' with ''\nunify_rule: ['6'] with ''\nunify_key: '6' with ''\nunify_rule: ['7'] with ''\nunify_key: '7' with ''\nunify_rule: ['8'] with ''\nunify_key: '8' with ''\nunify_rule: ['9'] with ''\nunify_key: '9' with ''\nunify_rule: ['<digit>'] with '2'\nunify_key: '<digit>' with '2'\nunify_rule: ['0'] with '2'\nunify_key: '0' with '2'\nunify_rule: ['1'] with '2'\nunify_key: '1' with '2'\nunify_rule: ['2'] with '2'\nunify_key: '2' with '2'\n\n```", "```py\n(2, [('<digit>', [('1', [])]), ('<integer>', [('<digit>', [('2', [])])])])\n\n```", "```py\nmystring = \"1 + 2\"\npeg = PEGParser(EXPR_GRAMMAR, log=False)\npeg.parse(mystring) \n```", "```py\n[('<start>',\n  [('<expr>',\n    [('<term>', [('<factor>', [('<integer>', [('<digit>', [('1', [])])])])]),\n     (' + ', []),\n     ('<expr>',\n      [('<term>',\n        [('<factor>', [('<integer>', [('<digit>', [('2', [])])])])])])])])]\n\n```", "```py\nfrom [functools](https://docs.python.org/3/library/functools.html) import lru_cache \n```", "```py\nclass PEGParser(PEGParser):\n    @lru_cache(maxsize=None)\n    def unify_key(self, key, text, at=0):\n        if key not in self.cgrammar:\n            if text[at:].startswith(key):\n                return at + len(key), (key, [])\n            else:\n                return at, None\n        for rule in self.cgrammar[key]:\n            to, res = self.unify_rule(rule, text, at)\n            if res is not None:\n                return (to, (key, res))\n        return 0, None \n```", "```py\nmystring = \"1 + (2 * 3)\"\npeg = PEGParser(EXPR_GRAMMAR)\nfor tree in peg.parse(mystring):\n    assert tree_to_string(tree) == mystring\n    display(display_tree(tree)) \n```", "```py\nmystring = \"1 * (2 + 3.35)\"\nfor tree in peg.parse(mystring):\n    assert tree_to_string(tree) == mystring\n    display(display_tree(tree)) \n```", "```py\nPEG_SURPRISE: Grammar = {\n    \"<A>\": [\"a<A>a\", \"aa\"]\n} \n```", "```py\nstrings = []\nfor nn in range(4):\n    f = GrammarFuzzer(PEG_SURPRISE, start_symbol='<A>')\n    tree = ('<A>', None)\n    for _ in range(nn):\n        tree = f.expand_tree_once(tree)\n    tree = f.expand_tree_with_strategy(tree, f.expand_node_min_cost)\n    strings.append(tree_to_string(tree))\n    display_tree(tree)\nstrings \n```", "```py\n['aa', 'aaaa', 'aaaaaa', 'aaaaaaaa']\n\n```", "```py\npeg = PEGParser(PEG_SURPRISE, start_symbol='<A>')\nfor s in strings:\n    with ExpectError():\n        for tree in peg.parse(s):\n            display_tree(tree)\n        print(s) \n```", "```py\naa\naaaa\naaaaaaaa\n\n```", "```py\nTraceback (most recent call last):\n  File \"/var/folders/n2/xd9445p97rb3xh7m1dfx8_4h0006ts/T/ipykernel_10601/3226632005.py\", line 4, in <module>\n    for tree in peg.parse(s):\n                ^^^^^^^^^^^^\n  File \"/var/folders/n2/xd9445p97rb3xh7m1dfx8_4h0006ts/T/ipykernel_10601/2022555909.py\", line 40, in parse\n    raise SyntaxError(\"at \" + repr(text[cursor:]))\nSyntaxError: at 'aa' (expected)\n\n```", "```py\ngrammar = {\n    '<start>': ['<A>', '<B>'],\n    ...\n}\n```", "```py\ngrammar = {\n    '<start>': ['<start_>'],\n    '<start_>': ['<A>', '<B>'],\n    ...\n}\n```", "```py\nSAMPLE_GRAMMAR: Grammar = {\n    '<start>': ['<A><B>'],\n    '<A>': ['a<B>c', 'a<A>'],\n    '<B>': ['b<C>', '<D>'],\n    '<C>': ['c'],\n    '<D>': ['d']\n}\nC_SAMPLE_GRAMMAR = canonical(SAMPLE_GRAMMAR) \n```", "```py\nsyntax_diagram(SAMPLE_GRAMMAR) \n```", "```py\nstart\n\n```", "```py\nA\n\n```", "```py\nB\n\n```", "```py\nC\n\n```", "```py\nD\n\n```", "```py\n<start> : ● <A> <B>\n```", "```py\n<A> : ● a <B> c\n<A> : ● a <A>\n```", "```py\n<A> : a ● <B> c\n<A> : a ● <A>\n<B> : ● b <C>\n<B> : ● <D>\n<A> : ● a <B> c\n<A> : ● a <A>\n<D> : ● d\n```", "```py\n<D> : d ●\n<B> : <D> ●\n<A> : a <B> ● c\n```", "```py\n<A> : a <B> c ●\n<start> : <A> ● <B>\n<B> : ● b <C>\n<B> : ● <D>\n<D> : ● d\n```", "```py\n<D> : d ●\n<B> : <D> ●\n<start> : <A> <B> ●\n```", "```py\nclass Column:\n    def __init__(self, index, letter):\n        self.index, self.letter = index, letter\n        self.states, self._unique = [], {}\n\n    def __str__(self):\n        return \"%s chart[%d]\\n%s\" % (self.letter, self.index, \"\\n\".join(\n            str(state) for state in self.states if state.finished())) \n```", "```py\nclass Column(Column):\n    def add(self, state):\n        if state in self._unique:\n            return self._unique[state]\n        self._unique[state] = state\n        self.states.append(state)\n        state.e_col = self\n        return self._unique[state] \n```", "```py\nclass Item:\n    def __init__(self, name, expr, dot):\n        self.name, self.expr, self.dot = name, expr, dot \n```", "```py\nclass Item(Item):\n    def finished(self):\n        return self.dot >= len(self.expr)\n\n    def advance(self):\n        return Item(self.name, self.expr, self.dot + 1)\n\n    def at_dot(self):\n        return self.expr[self.dot] if self.dot < len(self.expr) else None \n```", "```py\nitem_name = '<B>'\nitem_expr = C_SAMPLE_GRAMMAR[item_name][1]\nan_item = Item(item_name, tuple(item_expr), 0) \n```", "```py\nan_item.at_dot() \n```", "```py\n'<D>'\n\n```", "```py\nanother_item = an_item.advance() \n```", "```py\nanother_item.finished() \n```", "```py\nTrue\n\n```", "```py\nclass State(Item):\n    def __init__(self, name, expr, dot, s_col, e_col=None):\n        super().__init__(name, expr, dot)\n        self.s_col, self.e_col = s_col, e_col\n\n    def __str__(self):\n        def idx(var):\n            return var.index if var else -1\n\n        return self.name + ':= ' + ' '.join([\n            str(p)\n            for p in [*self.expr[:self.dot], '|', *self.expr[self.dot:]]\n        ]) + \"(%d,%d)\" % (idx(self.s_col), idx(self.e_col))\n\n    def copy(self):\n        return State(self.name, self.expr, self.dot, self.s_col, self.e_col)\n\n    def _t(self):\n        return (self.name, self.expr, self.dot, self.s_col.index)\n\n    def __hash__(self):\n        return hash(self._t())\n\n    def __eq__(self, other):\n        return self._t() == other._t()\n\n    def advance(self):\n        return State(self.name, self.expr, self.dot + 1, self.s_col) \n```", "```py\ncol_0 = Column(0, None)\nitem_tuple = tuple(*C_SAMPLE_GRAMMAR[START_SYMBOL])\nstart_state = State(START_SYMBOL, item_tuple, 0, col_0)\ncol_0.add(start_state)\nstart_state.at_dot() \n```", "```py\n'<A>'\n\n```", "```py\nsym = start_state.at_dot()\nfor alt in C_SAMPLE_GRAMMAR[sym]:\n    col_0.add(State(sym, tuple(alt), 0, col_0))\nfor s in col_0.states:\n    print(s) \n```", "```py\n<start>:= | <A> <B>(0,0)\n<A>:= | a <B> c(0,0)\n<A>:= | a <A>(0,0)\n\n```", "```py\n<start>: ● <A> <B>\n```", "```py\nclass EarleyParser(Parser):\n  \"\"\"Earley Parser. This parser can parse any context-free grammar.\"\"\"\n\n    def __init__(self, grammar: Grammar, **kwargs) -> None:\n        super().__init__(grammar, **kwargs)\n        self.chart: List = []  # for type checking\n\n    def chart_parse(self, words, start):\n        alt = tuple(*self.cgrammar[start])\n        chart = [Column(i, tok) for i, tok in enumerate([None, *words])]\n        chart[0].add(State(start, alt, 0, chart[0]))\n        return self.fill_chart(chart) \n```", "```py\n<A>: a  ●  <B> c\n```", "```py\n<A>: a ● <B> c\n<B>: ● b c\n<B>: ● <D>\n```", "```py\nclass EarleyParser(EarleyParser):\n    def predict(self, col, sym, state):\n        for alt in self.cgrammar[sym]:\n            col.add(State(sym, tuple(alt), 0, col)) \n```", "```py\ncol_0 = Column(0, None)\ncol_0.add(start_state)\nep = EarleyParser(SAMPLE_GRAMMAR)\nep.chart = [col_0] \n```", "```py\nfor s in ep.chart[0].states:\n    print(s) \n```", "```py\n<start>:= | <A> <B>(0,0)\n\n```", "```py\nep.predict(col_0, '<A>', s)\nfor s in ep.chart[0].states:\n    print(s) \n```", "```py\n<start>:= | <A> <B>(0,0)\n<A>:= | a <B> c(0,0)\n<A>:= | a <A>(0,0)\n\n```", "```py\n<B>: ● b c\n```", "```py\n<B>: b ● c\n```", "```py\nclass EarleyParser(EarleyParser):\n    def scan(self, col, state, letter):\n        if letter == col.letter:\n            col.add(state.advance()) \n```", "```py\nep = EarleyParser(SAMPLE_GRAMMAR)\ncol_1 = Column(1, 'a')\nep.chart = [col_0, col_1] \n```", "```py\nnew_state = ep.chart[0].states[1]\nprint(new_state) \n```", "```py\n<A>:= | a <B> c(0,0)\n\n```", "```py\nep.scan(col_1, new_state, 'a')\nfor s in ep.chart[1].states:\n    print(s) \n```", "```py\n<A>:= a | <B> c(0,1)\n\n```", "```py\n<A>: a ● <B> c\n<B>: b c ●\n```", "```py\nclass EarleyParser(EarleyParser):\n    def complete(self, col, state):\n        return self.earley_complete(col, state)\n\n    def earley_complete(self, col, state):\n        parent_states = [\n            st for st in state.s_col.states if st.at_dot() == state.name\n        ]\n        for st in parent_states:\n            col.add(st.advance()) \n```", "```py\nep = EarleyParser(SAMPLE_GRAMMAR)\ncol_1 = Column(1, 'a')\ncol_2 = Column(2, 'd')\nep.chart = [col_0, col_1, col_2]\nep.predict(col_0, '<A>', s)\nfor s in ep.chart[0].states:\n    print(s) \n```", "```py\n<start>:= | <A> <B>(0,0)\n<A>:= | a <B> c(0,0)\n<A>:= | a <A>(0,0)\n\n```", "```py\nfor state in ep.chart[0].states:\n    if state.at_dot() not in SAMPLE_GRAMMAR:\n        ep.scan(col_1, state, 'a')\nfor s in ep.chart[1].states:\n    print(s) \n```", "```py\n<A>:= a | <B> c(0,1)\n<A>:= a | <A>(0,1)\n\n```", "```py\nfor state in ep.chart[1].states:\n    if state.at_dot() in SAMPLE_GRAMMAR:\n        ep.predict(col_1, state.at_dot(), state)\nfor s in ep.chart[1].states:\n    print(s) \n```", "```py\n<A>:= a | <B> c(0,1)\n<A>:= a | <A>(0,1)\n<B>:= | b <C>(1,1)\n<B>:= | <D>(1,1)\n<A>:= | a <B> c(1,1)\n<A>:= | a <A>(1,1)\n<D>:= | d(1,1)\n\n```", "```py\nfor state in ep.chart[1].states:\n    if state.at_dot() not in SAMPLE_GRAMMAR:\n        ep.scan(col_2, state, state.at_dot())\n\nfor s in ep.chart[2].states:\n    print(s) \n```", "```py\n<D>:= d |(1,2)\n\n```", "```py\nfor state in ep.chart[2].states:\n    if state.finished():\n        ep.complete(col_2, state)\n\nfor s in ep.chart[2].states:\n    print(s) \n```", "```py\n<D>:= d |(1,2)\n<B>:= <D> |(1,2)\n<A>:= a <B> | c(0,2)\n\n```", "```py\nclass EarleyParser(EarleyParser):\n    def fill_chart(self, chart):\n        for i, col in enumerate(chart):\n            for state in col.states:\n                if state.finished():\n                    self.complete(col, state)\n                else:\n                    sym = state.at_dot()\n                    if sym in self.cgrammar:\n                        self.predict(col, sym, state)\n                    else:\n                        if i + 1 >= len(chart):\n                            continue\n                        self.scan(chart[i + 1], state, sym)\n            if self.log:\n                print(col, '\\n')\n        return chart \n```", "```py\nep = EarleyParser(SAMPLE_GRAMMAR, log=True)\ncolumns = ep.chart_parse('adcd', START_SYMBOL) \n```", "```py\nNone chart[0]\n\na chart[1]\n\nd chart[2]\n<D>:= d |(1,2)\n<B>:= <D> |(1,2) \n\nc chart[3]\n<A>:= a <B> c |(0,3) \n\nd chart[4]\n<D>:= d |(3,4)\n<B>:= <D> |(3,4)\n<start>:= <A> <B> |(0,4) \n\n```", "```py\nlast_col = columns[-1]\nfor state in last_col.states:\n    if state.name == '<start>':\n        print(state) \n```", "```py\n<start>:= <A> <B> |(0,4)\n\n```", "```py\nclass EarleyParser(EarleyParser):\n    def parse_prefix(self, text):\n        self.table = self.chart_parse(text, self.start_symbol())\n        for col in reversed(self.table):\n            states = [\n                st for st in col.states if st.name == self.start_symbol()\n            ]\n            if states:\n                return col.index, states\n        return -1, [] \n```", "```py\nep = EarleyParser(SAMPLE_GRAMMAR)\ncursor, last_states = ep.parse_prefix('adcd')\nprint(cursor, [str(s) for s in last_states]) \n```", "```py\n4 ['<start>:= <A> <B> |(0,4)']\n\n```", "```py\nclass EarleyParser(EarleyParser):\n    def parse(self, text):\n        cursor, states = self.parse_prefix(text)\n        start = next((s for s in states if s.finished()), None)\n\n        if cursor < len(text) or not start:\n            raise SyntaxError(\"at \" + repr(text[cursor:]))\n\n        forest = self.parse_forest(self.table, start)\n        for tree in self.extract_trees(forest):\n            yield self.prune_tree(tree) \n```", "```py\nclass EarleyParser(EarleyParser):\n    def parse_paths(self, named_expr, chart, frm, til):\n        def paths(state, start, k, e):\n            if not e:\n                return [[(state, k)]] if start == frm else []\n            else:\n                return [[(state, k)] + r\n                        for r in self.parse_paths(e, chart, frm, start)]\n\n        *expr, var = named_expr\n        starts = None\n        if var not in self.cgrammar:\n            starts = ([(var, til - len(var),\n                        't')] if til > 0 and chart[til].letter == var else [])\n        else:\n            starts = [(s, s.s_col.index, 'n') for s in chart[til].states\n                      if s.finished() and s.name == var]\n\n        return [p for s, start, k in starts for p in paths(s, start, k, expr)] \n```", "```py\nprint(SAMPLE_GRAMMAR['<start>'])\nep = EarleyParser(SAMPLE_GRAMMAR)\ncompleted_start = last_states[0]\npaths = ep.parse_paths(completed_start.expr, columns, 0, 4)\nfor path in paths:\n    print([list(str(s_) for s_ in s) for s in path]) \n```", "```py\n['<A><B>']\n[['<B>:= <D> |(3,4)', 'n'], ['<A>:= a <B> c |(0,3)', 'n']]\n\n```", "```py\nclass EarleyParser(EarleyParser):\n    def forest(self, s, kind, chart):\n        return self.parse_forest(chart, s) if kind == 'n' else (s, [])\n\n    def parse_forest(self, chart, state):\n        pathexprs = self.parse_paths(state.expr, chart, state.s_col.index,\n                                     state.e_col.index) if state.expr else []\n        return state.name, [[(v, k, chart) for v, k in reversed(pathexpr)]\n                            for pathexpr in pathexprs] \n```", "```py\nep = EarleyParser(SAMPLE_GRAMMAR)\nresult = ep.parse_forest(columns, last_states[0])\nresult \n```", "```py\n('<start>',\n [[(<__main__.State at 0x1071c37d0>,\n    'n',\n    [<__main__.Column at 0x1071c2810>,\n     <__main__.Column at 0x1071c27e0>,\n     <__main__.Column at 0x1071c29f0>,\n     <__main__.Column at 0x1071c1be0>,\n     <__main__.Column at 0x1071c30e0>]),\n   (<__main__.State at 0x1071c3980>,\n    'n',\n    [<__main__.Column at 0x1071c2810>,\n     <__main__.Column at 0x1071c27e0>,\n     <__main__.Column at 0x1071c29f0>,\n     <__main__.Column at 0x1071c1be0>,\n     <__main__.Column at 0x1071c30e0>])]])\n\n```", "```py\nclass EarleyParser(EarleyParser):\n    def extract_a_tree(self, forest_node):\n        name, paths = forest_node\n        if not paths:\n            return (name, [])\n        return (name, [self.extract_a_tree(self.forest(*p)) for p in paths[0]])\n\n    def extract_trees(self, forest):\n        yield self.extract_a_tree(forest) \n```", "```py\nA3_GRAMMAR: Grammar = {\n    \"<start>\": [\"<bexpr>\"],\n    \"<bexpr>\": [\n        \"<aexpr><gt><aexpr>\", \"<aexpr><lt><aexpr>\", \"<aexpr>=<aexpr>\",\n        \"<bexpr>=<bexpr>\", \"<bexpr>&<bexpr>\", \"<bexpr>|<bexpr>\", \"(<bexrp>)\"\n    ],\n    \"<aexpr>\":\n    [\"<aexpr>+<aexpr>\", \"<aexpr>-<aexpr>\", \"(<aexpr>)\", \"<integer>\"],\n    \"<integer>\": [\"<digit><integer>\", \"<digit>\"],\n    \"<digit>\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n    \"<lt>\": ['<'],\n    \"<gt>\": ['>']\n} \n```", "```py\nsyntax_diagram(A3_GRAMMAR) \n```", "```py\nstart\n\n```", "```py\nbexpr\n\n```", "```py\naexpr\n\n```", "```py\ninteger\n\n```", "```py\ndigit\n\n```", "```py\nlt\n\n```", "```py\ngt\n\n```", "```py\nmystring = '(1+24)=33'\nparser = EarleyParser(A3_GRAMMAR)\nfor tree in parser.parse(mystring):\n    assert tree_to_string(tree) == mystring\n    display_tree(tree) \n```", "```py\nimport [itertools](https://docs.python.org/3/library/itertools.html) as [I](I.html) \n```", "```py\nclass EarleyParser(EarleyParser):\n    def extract_trees(self, forest_node):\n        name, paths = forest_node\n        if not paths:\n            yield (name, [])\n\n        for path in paths:\n            ptrees = [self.extract_trees(self.forest(*p)) for p in path]\n            for p in I.product(*ptrees):\n                yield (name, p) \n```", "```py\nmystring = '1+2'\nparser = EarleyParser(A1_GRAMMAR)\nfor tree in parser.parse(mystring):\n    assert mystring == tree_to_string(tree)\n    display_tree(tree) \n```", "```py\ngf = GrammarFuzzer(A1_GRAMMAR)\nfor i in range(5):\n    s = gf.fuzz()\n    print(i, s)\n    for tree in parser.parse(s):\n        assert tree_to_string(tree) == s \n```", "```py\n0 045+3+2-9+7-7-5-1-449\n1 0+9+5-2+1-8+4-3+7+2\n2 76413\n3 9339\n4 62\n\n```", "```py\nE_GRAMMAR_1: Grammar = {\n    '<start>': ['<A>', '<B>'],\n    '<A>': ['a', ''],\n    '<B>': ['b']\n} \n```", "```py\nEPSILON = ''\nE_GRAMMAR: Grammar = {\n    '<start>': ['<S>'],\n    '<S>': ['<A><A><A><A>'],\n    '<A>': ['a', '<E>'],\n    '<E>': [EPSILON]\n} \n```", "```py\nsyntax_diagram(E_GRAMMAR) \n```", "```py\nstart\n\n```", "```py\nS\n\n```", "```py\nA\n\n```", "```py\nE\n\n```", "```py\nmystring = 'a'\nparser = EarleyParser(E_GRAMMAR)\nwith ExpectError():\n    trees = parser.parse(mystring) \n```", "```py\ndef fixpoint(f):\n    def helper(arg):\n        while True:\n            sarg = str(arg)\n            arg_ = f(arg)\n            if str(arg_) == sarg:\n                return arg\n            arg = arg_\n\n    return helper \n```", "```py\ndef my_sqrt(x):\n    @fixpoint\n    def _my_sqrt(approx):\n        return (approx + x / approx) / 2\n\n    return _my_sqrt(1) \n```", "```py\nmy_sqrt(2) \n```", "```py\n1.414213562373095\n\n```", "```py\ndef rules(grammar):\n    return [(key, choice)\n            for key, choices in grammar.items()\n            for choice in choices] \n```", "```py\ndef terminals(grammar):\n    return set(token\n               for key, choice in rules(grammar)\n               for token in choice if token not in grammar) \n```", "```py\ndef nullable_expr(expr, nullables):\n    return all(token in nullables for token in expr) \n```", "```py\ndef nullable(grammar):\n    productions = rules(grammar)\n\n    @fixpoint\n    def nullable_(nullables):\n        for A, expr in productions:\n            if nullable_expr(expr, nullables):\n                nullables |= {A}\n        return (nullables)\n\n    return nullable_({EPSILON}) \n```", "```py\nfor key, grammar in {\n        'E_GRAMMAR': E_GRAMMAR,\n        'E_GRAMMAR_1': E_GRAMMAR_1\n}.items():\n    print(key, nullable(canonical(grammar))) \n```", "```py\nE_GRAMMAR {'', '<start>', '<S>', '<E>', '<A>'}\nE_GRAMMAR_1 {'', '<start>', '<A>'}\n\n```", "```py\nclass EarleyParser(EarleyParser):\n    def __init__(self, grammar, **kwargs):\n        super().__init__(grammar, **kwargs)\n        self.epsilon = nullable(self.cgrammar)\n\n    def predict(self, col, sym, state):\n        for alt in self.cgrammar[sym]:\n            col.add(State(sym, tuple(alt), 0, col))\n        if sym in self.epsilon:\n            col.add(state.advance()) \n```", "```py\nmystring = 'a'\nparser = EarleyParser(E_GRAMMAR)\nfor tree in parser.parse(mystring):\n    display_tree(tree) \n```", "```py\nDIRECTLY_SELF_REFERRING: Grammar = {\n    '<start>': ['<query>'],\n    '<query>': ['select <expr> from a'],\n    \"<expr>\": [\"<expr>\", \"a\"],\n}\nINDIRECTLY_SELF_REFERRING: Grammar = {\n    '<start>': ['<query>'],\n    '<query>': ['select <expr> from a'],\n    \"<expr>\": [\"<aexpr>\", \"a\"],\n    \"<aexpr>\": [\"<expr>\"],\n} \n```", "```py\nmystring = 'select a from a'\nfor grammar in [DIRECTLY_SELF_REFERRING, INDIRECTLY_SELF_REFERRING]:\n    forest = EarleyParser(grammar).parse(mystring)\n    print('recognized', mystring)\n    try:\n        for tree in forest:\n            print(tree_to_string(tree))\n    except RecursionError as e:\n        print(\"Recursion error\", e) \n```", "```py\nrecognized select a from a\nRecursion error maximum recursion depth exceeded\nrecognized select a from a\nRecursion error maximum recursion depth exceeded\n\n```", "```py\nclass SimpleExtractor:\n    def __init__(self, parser, text):\n        self.parser = parser\n        cursor, states = parser.parse_prefix(text)\n        start = next((s for s in states if s.finished()), None)\n        if cursor < len(text) or not start:\n            raise SyntaxError(\"at \" + repr(cursor))\n        self.my_forest = parser.parse_forest(parser.table, start)\n\n    def extract_a_node(self, forest_node):\n        name, paths = forest_node\n        if not paths:\n            return ((name, 0, 1), []), (name, [])\n        cur_path, i, length = self.choose_path(paths)\n        child_nodes = []\n        pos_nodes = []\n        for s, kind, chart in cur_path:\n            f = self.parser.forest(s, kind, chart)\n            postree, ntree = self.extract_a_node(f)\n            child_nodes.append(ntree)\n            pos_nodes.append(postree)\n\n        return ((name, i, length), pos_nodes), (name, child_nodes)\n\n    def choose_path(self, arr):\n        length = len(arr)\n        i = random.randrange(length)\n        return arr[i], i, length\n\n    def extract_a_tree(self):\n        pos_tree, parse_tree = self.extract_a_node(self.my_forest)\n        return self.parser.prune_tree(parse_tree) \n```", "```py\nde = SimpleExtractor(EarleyParser(DIRECTLY_SELF_REFERRING), mystring) \n```", "```py\nfor i in range(5):\n    tree = de.extract_a_tree()\n    print(tree_to_string(tree)) \n```", "```py\nselect a from a\nselect a from a\nselect a from a\nselect a from a\nselect a from a\n\n```", "```py\nie = SimpleExtractor(EarleyParser(INDIRECTLY_SELF_REFERRING), mystring) \n```", "```py\nfor i in range(5):\n    tree = ie.extract_a_tree()\n    print(tree_to_string(tree)) \n```", "```py\nselect a from a\nselect a from a\nselect a from a\nselect a from a\nselect a from a\n\n```", "```py\nclass ChoiceNode:\n    def __init__(self, parent, total):\n        self._p, self._chosen = parent, 0\n        self._total, self.next = total, None\n\n    def chosen(self):\n        assert not self.finished()\n        return self._chosen\n\n    def __str__(self):\n        return '%d(%s/%s  %s)' % (self._i, str(self._chosen),\n                                 str(self._total), str(self.next))\n\n    def __repr__(self):\n        return repr((self._i, self._chosen, self._total))\n\n    def increment(self):\n        # as soon as we increment, next becomes invalid\n        self.next = None\n        self._chosen += 1\n        if self.finished():\n            if self._p is None:\n                return None\n            return self._p.increment()\n        return self\n\n    def finished(self):\n        return self._chosen >= self._total \n```", "```py\nclass EnhancedExtractor(SimpleExtractor):\n    def __init__(self, parser, text):\n        super().__init__(parser, text)\n        self.choices = ChoiceNode(None, 1) \n```", "```py\nclass EnhancedExtractor(EnhancedExtractor):\n    def choose_path(self, arr, choices):\n        arr_len = len(arr)\n        if choices.next is not None:\n            if choices.next.finished():\n                return None, None, None, choices.next\n        else:\n            choices.next = ChoiceNode(choices, arr_len)\n        next_choice = choices.next.chosen()\n        choices = choices.next\n        return arr[next_choice], next_choice, arr_len, choices \n```", "```py\nclass EnhancedExtractor(EnhancedExtractor):\n    def extract_a_node(self, forest_node, seen, choices):\n        name, paths = forest_node\n        if not paths:\n            return (name, []), choices\n\n        cur_path, _i, _l, new_choices = self.choose_path(paths, choices)\n        if cur_path is None:\n            return None, new_choices\n        child_nodes = []\n        for s, kind, chart in cur_path:\n            if kind == 't':\n                child_nodes.append((s, []))\n                continue\n            nid = (s.name, s.s_col.index, s.e_col.index)\n            if nid in seen:\n                return None, new_choices\n            f = self.parser.forest(s, kind, chart)\n            ntree, newer_choices = self.extract_a_node(f, seen | {nid}, new_choices)\n            if ntree is None:\n                return None, newer_choices\n            child_nodes.append(ntree)\n            new_choices = newer_choices\n        return (name, child_nodes), new_choices \n```", "```py\nclass EnhancedExtractor(EnhancedExtractor):\n    def extract_a_tree(self):\n        while not self.choices.finished():\n            parse_tree, choices = self.extract_a_node(self.my_forest, set(), self.choices)\n            choices.increment()\n            if parse_tree is not None:\n                return self.parser.prune_tree(parse_tree)\n        return None \n```", "```py\nee = EnhancedExtractor(EarleyParser(INDIRECTLY_SELF_REFERRING), mystring) \n```", "```py\ni = 0\nwhile True:\n    i += 1\n    t = ee.extract_a_tree()\n    if t is None: break\n    print(i, t)\n    s = tree_to_string(t)\n    assert s == mystring \n```", "```py\n1 ('<start>', [('<query>', [('select ', []), ('<expr>', [('a', [])]), (' from a', [])])])\n\n```", "```py\nistring = '1+2+3+4'\nee = EnhancedExtractor(EarleyParser(A1_GRAMMAR), istring) \n```", "```py\ni = 0\nwhile True:\n    i += 1\n    t = ee.extract_a_tree()\n    if t is None: break\n    print(i, t)\n    s = tree_to_string(t)\n    assert s == istring \n```", "```py\n1 ('<start>', [('<expr>', [('<expr>', [('<expr>', [('<expr>', [('<integer>', [('<digit>', [('1', [])])])]), ('+', []), ('<expr>', [('<integer>', [('<digit>', [('2', [])])])])]), ('+', []), ('<expr>', [('<integer>', [('<digit>', [('3', [])])])])]), ('+', []), ('<expr>', [('<integer>', [('<digit>', [('4', [])])])])])])\n2 ('<start>', [('<expr>', [('<expr>', [('<expr>', [('<integer>', [('<digit>', [('1', [])])])]), ('+', []), ('<expr>', [('<expr>', [('<integer>', [('<digit>', [('2', [])])])]), ('+', []), ('<expr>', [('<integer>', [('<digit>', [('3', [])])])])])]), ('+', []), ('<expr>', [('<integer>', [('<digit>', [('4', [])])])])])])\n3 ('<start>', [('<expr>', [('<expr>', [('<expr>', [('<integer>', [('<digit>', [('1', [])])])]), ('+', []), ('<expr>', [('<integer>', [('<digit>', [('2', [])])])])]), ('+', []), ('<expr>', [('<expr>', [('<integer>', [('<digit>', [('3', [])])])]), ('+', []), ('<expr>', [('<integer>', [('<digit>', [('4', [])])])])])])])\n4 ('<start>', [('<expr>', [('<expr>', [('<integer>', [('<digit>', [('1', [])])])]), ('+', []), ('<expr>', [('<expr>', [('<expr>', [('<integer>', [('<digit>', [('2', [])])])]), ('+', []), ('<expr>', [('<integer>', [('<digit>', [('3', [])])])])]), ('+', []), ('<expr>', [('<integer>', [('<digit>', [('4', [])])])])])])])\n5 ('<start>', [('<expr>', [('<expr>', [('<integer>', [('<digit>', [('1', [])])])]), ('+', []), ('<expr>', [('<expr>', [('<integer>', [('<digit>', [('2', [])])])]), ('+', []), ('<expr>', [('<expr>', [('<integer>', [('<digit>', [('3', [])])])]), ('+', []), ('<expr>', [('<integer>', [('<digit>', [('4', [])])])])])])])])\n\n```", "```py\nmystring = \"1 + (2 * 3)\"\nearley = EarleyParser(EXPR_GRAMMAR)\nfor tree in earley.parse(mystring):\n    assert tree_to_string(tree) == mystring\n    display(display_tree(tree)) \n```", "```py\nmystring = \"1 * (2 + 3.35)\"\nfor tree in earley.parse(mystring):\n    assert tree_to_string(tree) == mystring\n    display(display_tree(tree)) \n```", "```py\ndef prod_line_grammar(nonterminals, terminals):\n    g = {\n        '<start>': ['<symbols>'],\n        '<symbols>': ['<symbol><symbols>', '<symbol>'],\n        '<symbol>': ['<nonterminals>', '<terminals>'],\n        '<nonterminals>': ['<lt><alpha><gt>'],\n        '<lt>': ['<'],\n        '<gt>': ['>'],\n        '<alpha>': nonterminals,\n        '<terminals>': terminals\n    }\n\n    if not nonterminals:\n        g['<nonterminals>'] = ['']\n        del g['<lt>']\n        del g['<alpha>']\n        del g['<gt>']\n\n    return g \n```", "```py\nsyntax_diagram(prod_line_grammar([\"A\", \"B\", \"C\"], [\"1\", \"2\", \"3\"])) \n```", "```py\nstart\n\n```", "```py\nsymbols\n\n```", "```py\nsymbol\n\n```", "```py\nnonterminals\n\n```", "```py\nlt\n\n```", "```py\ngt\n\n```", "```py\nalpha\n\n```", "```py\nterminals\n\n```", "```py\ndef make_rule(nonterminals, terminals, num_alts):\n    prod_grammar = prod_line_grammar(nonterminals, terminals)\n\n    gf = GrammarFuzzer(prod_grammar, min_nonterminals=3, max_nonterminals=5)\n    name = \"<%s>\" % ''.join(random.choices(string.ascii_uppercase, k=3))\n\n    return (name, [gf.fuzz() for _ in range(num_alts)]) \n```", "```py\nmake_rule([\"A\", \"B\", \"C\"], [\"1\", \"2\", \"3\"], 3) \n```", "```py\n('<FYU>', ['<C>23', '<C><A>', '<B><C>3'])\n\n```", "```py\nfrom [Grammars](Grammars.html) import unreachable_nonterminals \n```", "```py\ndef make_grammar(num_symbols=3, num_alts=3):\n    terminals = list(string.ascii_lowercase)\n    grammar = {}\n    name = None\n    for _ in range(num_symbols):\n        nonterminals = [k[1:-1] for k in grammar.keys()]\n        name, expansions = \\\n            make_rule(nonterminals, terminals, num_alts)\n        grammar[name] = expansions\n\n    grammar[START_SYMBOL] = [name]\n\n    # Remove unused parts\n    for nonterminal in unreachable_nonterminals(grammar):\n        del grammar[nonterminal]\n\n    assert is_valid_grammar(grammar)\n\n    return grammar \n```", "```py\nmake_grammar() \n```", "```py\n{'<ILY>': ['lhp', 'gta', 'sm'],\n '<FZD>': ['qn<ILY>', 'e<ILY><ILY>g', '<ILY>f<ILY>m'],\n '<ITK>': ['<ILY>fyy', '<ILY><ILY>t', '<FZD>l<ILY>ao'],\n '<start>': ['<ITK>']}\n\n```", "```py\nfor i in range(5):\n    my_grammar = make_grammar()\n    print(my_grammar)\n    parser = EarleyParser(my_grammar)\n    mygf = GrammarFuzzer(my_grammar)\n    s = mygf.fuzz()\n    print(s)\n    for tree in parser.parse(s):\n        assert tree_to_string(tree) == s\n        display_tree(tree) \n```", "```py\n{'<SCS>': ['ts', 'f', 'ng'], '<BQN>': ['wm<SCS>', '<SCS>wi', '<SCS>hw'], '<UZC>': ['gyk<BQN>br', '<SCS>iqp', '<BQN>vb'], '<start>': ['<UZC>']}\nfhwvb\n{'<CRN>': ['meze', 'de', 'cpcv'], '<AIS>': ['<CRN>hb', 'dc<CRN>', 'pa<CRN>x'], '<MAO>': ['<CRN>su', '<CRN>hj', '<CRN><AIS>g'], '<start>': ['<MAO>']}\ndehj\n{'<MFY>': ['y', 'w', ''], '<ZOY>': ['oe<MFY>', 'h<MFY>u', 'lowr'], '<HFT>': ['<ZOY>ro', '<ZOY>w', '<ZOY><ZOY>w'], '<start>': ['<HFT>']}\nlowrro\n{'<CYC>': ['cg', 'enl', 'ovd'], '<TUV>': ['<CYC>hf', '<CYC>nl', 'fhg'], '<MOQ>': ['g<TUV>g', '<CYC>ix', '<CYC><TUV><CYC>'], '<start>': ['<MOQ>']}\ncgix\n{'<WJJ>': ['dszdlh', 'j', 'fd'], '<RQM>': ['<WJJ>wx', 'xs<WJJ><WJJ>', '<WJJ>x'], '<JNY>': ['<WJJ>oa', '<WJJ><WJJ>cx', 'xd<RQM>'], '<start>': ['<JNY>']}\njoa\n\n```", "```py\nmystring = 'aaaaaa' \n```", "```py\nresult = EarleyParser(LR_GRAMMAR, log=True).parse(mystring)\nfor _ in result: pass # consume the generator so that we can see the logs \n```", "```py\nNone chart[0]\n<A>:= |(0,0)\n<start>:= <A> |(0,0) \n\na chart[1]\n<A>:= <A> a |(0,1)\n<start>:= <A> |(0,1) \n\na chart[2]\n<A>:= <A> a |(0,2)\n<start>:= <A> |(0,2) \n\na chart[3]\n<A>:= <A> a |(0,3)\n<start>:= <A> |(0,3) \n\na chart[4]\n<A>:= <A> a |(0,4)\n<start>:= <A> |(0,4) \n\na chart[5]\n<A>:= <A> a |(0,5)\n<start>:= <A> |(0,5) \n\na chart[6]\n<A>:= <A> a |(0,6)\n<start>:= <A> |(0,6) \n\n```", "```py\nresult = EarleyParser(RR_GRAMMAR, log=True).parse(mystring)\nfor _ in result: pass \n```", "```py\nNone chart[0]\n<A>:= |(0,0)\n<start>:= <A> |(0,0) \n\na chart[1]\n<A>:= |(1,1)\n<A>:= a <A> |(0,1)\n<start>:= <A> |(0,1) \n\na chart[2]\n<A>:= |(2,2)\n<A>:= a <A> |(1,2)\n<A>:= a <A> |(0,2)\n<start>:= <A> |(0,2) \n\na chart[3]\n<A>:= |(3,3)\n<A>:= a <A> |(2,3)\n<A>:= a <A> |(1,3)\n<A>:= a <A> |(0,3)\n<start>:= <A> |(0,3) \n\na chart[4]\n<A>:= |(4,4)\n<A>:= a <A> |(3,4)\n<A>:= a <A> |(2,4)\n<A>:= a <A> |(1,4)\n<A>:= a <A> |(0,4)\n<start>:= <A> |(0,4) \n\na chart[5]\n<A>:= |(5,5)\n<A>:= a <A> |(4,5)\n<A>:= a <A> |(3,5)\n<A>:= a <A> |(2,5)\n<A>:= a <A> |(1,5)\n<A>:= a <A> |(0,5)\n<start>:= <A> |(0,5) \n\na chart[6]\n<A>:= |(6,6)\n<A>:= a <A> |(5,6)\n<A>:= a <A> |(4,6)\n<A>:= a <A> |(3,6)\n<A>:= a <A> |(2,6)\n<A>:= a <A> |(1,6)\n<A>:= a <A> |(0,6)\n<start>:= <A> |(0,6) \n\n```", "```py\n<C> : seq_3 <B> ● (s_3, e)  \n             |  constraints satisfied by <C> : seq_3 ● <B> (s_3, s_2)\n            <B> : seq_2 <A> ● (s_2, e)  \n                         | constraints satisfied by <B> : seq_2 ● <A> (s_2, s_1)\n                        <A> : seq_1 ● (s_1, e)\n```", "```py\n<C> : seq_3 ● <B> (s_3, s_2)  -->              <C> : seq_3 <B> ● (s_3, e)\n               |\n              <B> : seq_2 ● <A> (s_2, s_1) --> <B> : seq_2 <A> ● (s_2, e)  \n                             |\n                            <A> : seq_1 ●                        (s_1, e)\n```", "```py\nclass LeoParser(EarleyParser):\n    def complete(self, col, state):\n        return self.leo_complete(col, state)\n\n    def leo_complete(self, col, state):\n        detred = self.deterministic_reduction(state)\n        if detred:\n            col.add(detred.copy())\n        else:\n            self.earley_complete(col, state)\n\n    def deterministic_reduction(self, state):\n        raise NotImplementedError \n```", "```py\nRECURSION_GRAMMAR: Grammar = {\n    \"<start>\": [\"<A>\"],\n    \"<A>\": [\"<A>\", \"<A>aa\", \"AA\", \"<B>\"],\n    \"<B>\": [\"<C>\", \"<C>cc\", \"CC\"],\n    \"<C>\": [\"<B>\", \"<B>bb\", \"BB\"]\n} \n```", "```py\nfrom [ExpectError](ExpectError.html) import ExpectTimeout \n```", "```py\nwith ExpectTimeout(1, print_traceback=False):\n    mystring = 'AA'\n    parser = LeoParser(RECURSION_GRAMMAR)\n    tree, *_ = parser.parse(mystring)\n    assert tree_to_string(tree) == mystring\n    display_tree(tree) \n```", "```py\nRecursionError: maximum recursion depth exceeded (expected)\n\n```", "```py\nclass LL1Parser(Parser):\n    def parse_table(self):\n        self.my_rules = rules(self.cgrammar)\n        self.table = ...          # fill in here to produce\n\n    def rules(self):\n        for i, rule in enumerate(self.my_rules):\n            print(i, rule)\n\n    def show_table(self):\n        ts = list(sorted(terminals(self.cgrammar)))\n        print('Rule Name\\t| %s' % ' | '.join(t for t in ts))\n        for k in self.table:\n            pr = self.table[k]\n            actions = list(str(pr[t]) if t in pr else ' ' for t in ts)\n            print('%s  \\t| %s' % (k, ' | '.join(actions))) \n```", "```py\nfor i, r in enumerate(rules(canonical(A2_GRAMMAR))):\n    print(\"%d\\t  %s := %s\" % (i, r[0], r[1])) \n```", "```py\n0\t <start> := ['<expr>']\n1\t <expr> := ['<integer>', '<expr_>']\n2\t <expr_> := ['+', '<expr>']\n3\t <expr_> := ['-', '<expr>']\n4\t <expr_> := []\n5\t <integer> := ['<digit>', '<integer_>']\n6\t <integer_> := ['<integer>']\n7\t <integer_> := []\n8\t <digit> := ['0']\n9\t <digit> := ['1']\n10\t <digit> := ['2']\n11\t <digit> := ['3']\n12\t <digit> := ['4']\n13\t <digit> := ['5']\n14\t <digit> := ['6']\n15\t <digit> := ['7']\n16\t <digit> := ['8']\n17\t <digit> := ['9']\n\n```", "```py\n@incollection{fuzzingbook2024:Parser,\n    author = {Andreas Zeller and Rahul Gopinath and Marcel B{\\\"o}hme and Gordon Fraser and Christian Holler},\n    booktitle = {The Fuzzing Book},\n    title = {Parsing Inputs},\n    year = {2024},\n    publisher = {CISPA Helmholtz Center for Information Security},\n    howpublished = {\\url{https://www.fuzzingbook.org/html/Parser.html}},\n    note = {Retrieved 2024-11-09 17:07:29+01:00},\n    url = {https://www.fuzzingbook.org/html/Parser.html},\n    urldate = {2024-11-09 17:07:29+01:00}\n}\n\n```"]